{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a79c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍷 WINE OCR LEARNING LAB - STUDENT VERSION\n",
      "Your mission: Fill in the missing code to build a complete system!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from text_generator import TextGenerator\n",
    "from robust_text_generator import RobustTextImageGenerator\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "print(\"🍷 WINE OCR LEARNING LAB - STUDENT VERSION\")\n",
    "print(\"Your mission: Fill in the missing code to build a complete system!\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONSTS\n",
    "# =============================================================================\n",
    "\n",
    "VOCABULARY_MAX_SIZE = 100000  # Adjust as needed\n",
    "\n",
    "MENU_CHARACTERS = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz.,-*'&$%\"\n",
    "\n",
    "#(\n",
    "    \n",
    "#     \"0123456789\" +           # Years, prices\n",
    "#     \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" +  # Wine names (caps)\n",
    "#     \"abcdefghijklmnopqrstuvwxyz\" +  # Wine names (lowercase)\n",
    "#     \" .,-*'&$%\"                 # Punctuation\n",
    "# )\n",
    "\n",
    "\n",
    "char_to_idx = {char: idx for idx, char in enumerate(MENU_CHARACTERS)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(MENU_CHARACTERS)}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d23e4d-cb2e-4c6d-8adf-e2fe9aaa6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_cnn(img_width, img_height, output_size):\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        Input(shape=(img_width * img_height,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(output_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5abbaa-ddd5-47db-935c-491fd54cbabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text_regions_aggressive(image_path):\n",
    "  \"\"\"More aggressive text detection\"\"\"\n",
    "  img = cv2.imread(image_path)\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "  # Try multiple approaches\n",
    "  regions = []\n",
    "  \n",
    "  # Method 1: MSER (good for text)\n",
    "  mser = cv2.MSER_create()\n",
    "  regions_mser, _ = mser.detectRegions(gray)\n",
    "  \n",
    "  # Method 2: Threshold + contours\n",
    "  _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "  contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  \n",
    "  # Method 3: Adaptive threshold\n",
    "  adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "  contours_adaptive, _ = cv2.findContours(adaptive, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  \n",
    "  # Combine all contours\n",
    "  all_contours = list(contours) + list(contours_adaptive)\n",
    "  \n",
    "  for contour in all_contours:\n",
    "      x, y, w, h = cv2.boundingRect(contour)\n",
    "      \n",
    "      # MUCH more relaxed criteria\n",
    "      if w > 5 and h > 5 and w < img.shape[1]*0.8 and h < img.shape[0]*0.8:\n",
    "          regions.append((x, y, x+w, y+h))\n",
    "  \n",
    "  print(f\"Found {len(regions)} regions with aggressive detection\")\n",
    "  return regions\n",
    "\n",
    "# Test aggressive detection\n",
    "\n",
    "\n",
    "def detect_text_regions(image_path):\n",
    "    \"\"\"Find all text regions in wine menu image\"\"\"\n",
    "    \n",
    "    print(f\"🔍 Detecting text regions in {image_path}\")\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"❌ Could not load image: {image_path}\")\n",
    "        return [], None\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply threshold to get binary image\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours (potential text regions)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    text_boxes = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Filter by size - adjust these values based on your wine menu\n",
    "        # Text lines are usually: wide but not too tall\n",
    "        if w > 50 and h > 10 and w < 800 and h < 60:\n",
    "            text_boxes.append({\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': w,\n",
    "                'height': h\n",
    "            })\n",
    "    \n",
    "    # Sort by position (top to bottom, then left to right)\n",
    "    text_boxes = sorted(text_boxes, key=lambda box: (box['y'], box['x']))\n",
    "    \n",
    "    print(f\"✅ Found {len(text_boxes)} potential text regions\")\n",
    "    return text_boxes, image\n",
    "    \n",
    "def segment_characters_in_region(text_region_image):\n",
    "    \"\"\"Segment a text region into individual character images\"\"\"\n",
    "    \n",
    "    # Convert to grayscale if needed\n",
    "    if len(text_region_image.shape) == 3:\n",
    "        gray = cv2.cvtColor(text_region_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = text_region_image\n",
    "    \n",
    "    # Apply threshold to get binary image\n",
    "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find character contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Sort contours left to right\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "    \n",
    "    character_images = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Filter noise (too small)\n",
    "        if w > 3 and h > 5:\n",
    "            # Extract character\n",
    "            char_img = binary[y:y+h, x:x+w]\n",
    "            \n",
    "            # Resize to match your training data (32x48)\n",
    "            char_img_resized = cv2.resize(char_img, (32, 48))\n",
    "            \n",
    "            # Normalize to match training format\n",
    "            char_img_normalized = char_img_resized.astype(np.float32) / 255.0\n",
    "            \n",
    "            character_images.append(char_img_normalized)\n",
    "    \n",
    "    return character_images\n",
    "\n",
    "\n",
    "def recognize_text_with_cnn(text_region_image, cnn_model, char_to_idx, idx_to_char):\n",
    "    \"\"\"Use your trained CNN to recognize text in a region\"\"\"\n",
    "    \n",
    "    # Segment into characters\n",
    "    character_images = segment_characters_in_region(text_region_image)\n",
    "    \n",
    "    if len(character_images) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    # Recognize each character\n",
    "    recognized_text = \"\"\n",
    "    \n",
    "    for char_img in character_images:\n",
    "        # Flatten for your Dense model\n",
    "        char_input = char_img.flatten().reshape(1, -1)\n",
    "        \n",
    "        # Predict with your CNN\n",
    "        prediction = cnn_model.predict(char_input, verbose=0)\n",
    "        predicted_idx = np.argmax(prediction[0])\n",
    "        predicted_char = idx_to_char[predicted_idx]\n",
    "        \n",
    "        recognized_text += predicted_char\n",
    "    \n",
    "    return recognized_text\n",
    "\n",
    "\n",
    "\n",
    "def extract_all_spatial_text_cnn(image, text_boxes, cnn_model, char_to_idx, idx_to_char):\n",
    "    \"\"\"Extract text using your CNN model\"\"\"\n",
    "    \n",
    "    print(\"🔤 Extracting text with CNN model...\")\n",
    "    \n",
    "    spatial_text = []\n",
    "    \n",
    "    for i, box in enumerate(text_boxes):\n",
    "        # Extract the region\n",
    "        x, y, w, h = box['x'], box['y'], box['width'], box['height']\n",
    "        text_region = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Use CNN to recognize text\n",
    "        recognized_text = recognize_text_with_cnn(text_region, cnn_model, char_to_idx, idx_to_char)\n",
    "        \n",
    "        # Store with spatial info\n",
    "        spatial_text.append({\n",
    "            'text': recognized_text,\n",
    "            'x': box['x'],\n",
    "            'y': box['y'],\n",
    "            'width': box['width'],\n",
    "            'height': box['height'],\n",
    "            'box_id': i\n",
    "        })\n",
    "        \n",
    "        print(f\"  Box {i}: '{recognized_text}' at ({box['x']}, {box['y']})\")\n",
    "    \n",
    "    return spatial_text\n",
    "\n",
    "\n",
    "\n",
    "def visualize_text_detection(image, text_boxes, save_path=None):\n",
    "    \"\"\"Show detected text regions\"\"\"\n",
    "    if image is None:\n",
    "        print(f\"❌ Could not load image\")\n",
    "        return [], None\n",
    "\n",
    "    # Create copy for drawing\n",
    "    result_image = image.copy()\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for i, box in enumerate(text_boxes):\n",
    "        x, y, w, h = box['x'], box['y'], box['width'], box['height']\n",
    "        \n",
    "        # Draw green rectangle\n",
    "        cv2.rectangle(result_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Add box number\n",
    "        cv2.putText(result_image, str(i), (x, y-5), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Detected Text Regions ({len(text_boxes)} boxes)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print details\n",
    "    print(\"📋 Text Box Details:\")\n",
    "    for i, box in enumerate(text_boxes[:10]):  # Show first 10\n",
    "        print(f\"  Box {i}: x={box['x']}, y={box['y']}, size={box['width']}×{box['height']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef4b6e9-9c89-41a6-8d42-a48b9acd2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=32\n",
    "IMG_HEIGHT=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2f21f20-e5b2-4460-8716-94338aad46a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (63000, 1024)\n",
      "X flattened shape: (63000, 1024)\n",
      "✅ Batch generated, X: (63000, 1024), y: (63000, 70)\n",
      "   Y1: 0, 0, [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   Y2: 0, 0, [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "🔍 DATA VERIFICATION:\n",
      "Total samples: 50400\n",
      "Expected: 70 × 100 = 7000\n",
      "Unique classes: 70\n",
      "Samples per class: min=687, max=762, avg=720.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACcMAAACSCAYAAACD4EB9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfPJJREFUeJzt3Xe0XVXV//8ZkEASEhJKIKGFXqQJiEgzCNJBFKUoHaUJoggBBKVIbwMVUAQeQpcggg9NOpGOIgo8BhAIJZCQkIRUgoj8/vCX9f3syZ0r6557zj333Pt+jcEY8+bssnZbZZ/Dmr0++eSTTwwAAAAAAAAAAAAAAAAAgBY2X7MLAAAAAAAAAAAAAAAAAABAR/FjOAAAAAAAAAAAAAAAAABAy+PHcAAAAAAAAAAAAAAAAACAlseP4QAAAAAAAAAAAAAAAAAALY8fwwEAAAAAAAAAAAAAAAAAWh4/hgMAAAAAAAAAAAAAAAAAtDx+DAcAAAAAAAAAAAAAAAAAaHn8GA4AAAAAAAAAAAAAAAAA0PL4MRwAAAAAAAAAAAAAAAAAoOXxYzgAAAAAAAAAAAAAAHqw8847z1ZccUWbf/75bb311mt2cQAAqFm3/THcyJEjrVevXpV/GzNmjG233Xa28MIL26KLLmr77LOPTZo0qbLMww8/bL169bLXX3+9E0uLemjrmpcYNmyYnXLKKfUvEDpFdN33339/e/jhh4uXR2vQ6/ef//zHRo4cabvssostu+yy1q9fP1trrbXs9NNPtzlz5lTWe/31161Xr15t3hPo2vwzO3z4cOvVq1f6r3fv3rbCCivYwQcfbG+99VZ2XbSGtq75Wmut9anlHnjgAevbt6+tv/76NmXKFDOjTW9l83rW9b8XX3zRzOi3tzL67T3PvJ7xPn362DrrrGMXXXSR/ec//6msSz+u9ZU886eccooNGzascwqEhqAP1/O0p/+2+uqrh+uhNbR13T755BO79tprbYsttrCBAwda3759be2117bTTz/dZs+e/altDB8+3Pbff/9OKjHqpbR+V7TrrW3uNR87dqz17dvX9tprrzaXu+mmm6xXr152ySWXmNl/38cPHz68E0uKeitpo2nHuxd/Pe+9914bMWKEbbrppnbVVVfZmWeeaWb011td9Nzeeuuttv3229viiy9uvXv3tqFDh9ruu+9uDz74YFqG96+ty1/3p59+2g4//HDbYIMNbIEFFgjrct7DdQ9t9eF1LNZTrvNnml2AzjJu3DjbYostbJFFFrEzzzzTZs6caeeff749//zz9vTTT1vv3r2bXUQAHfT000/bKqusYoMGDar8+1NPPWWrrbaaDRw4sDkFQ0PMnj3bDjjgANt4443t0EMPtcGDB9sTTzxhJ598sj3wwAP24IMPMjDvppZZZhk766yzzMzsX//6l/3jH/+wX//613bPPffYmDFjrG/fvk0uIRrtwQcftJ133tlWW201u//++23RRRdtdpHQAPqsq6FDhzahNADqTZ/x9957z2644Qb74Q9/aJMmTbIzzjijyaUD0Aj04bq/qP+2yCKLNKE0aKSPP/7YvvWtb9moUaNs8803t1NOOcX69u1rjzzyiJ188sk2atQou//++23w4MHNLiqAGq2wwgp28skn2/HHH28HHHCAbbPNNumz6dOn2w9/+EP7whe+YIcddlgTSwmgnh588EGbb7757Morr+R7827sk08+sQMPPNBGjhxpn/vc5+zoo4+2pZZaysaPH2+33nqrbbXVVvbYY4/ZJpts0uyioo7uuusuu+KKK2ydddaxFVdc0V5++eVmFwlouB7zY7gzzzzTZs2aZc8884wtt9xyZma20UYb2Ve+8hUbOXKkHXzwwU0uIYCOevTRR22PPfaw888/38zMZs6caUcddZTde++9NmrUKH4M18307t37Ux3y7373uzZs2LD0g7itt966iSVEoyyyyCK29957V/5thRVWsCOOOMIee+wx+8pXvtKkkqEzjB492nbeeWdbddVV+RK1m2vrWQfQffhn/NBDD7XVV1/dfvnLX9ppp51m888/fxNLB6De6MP1DPTfeo5zzz3XRo0aZcccc4ydd9556d8PPvhg23333W3XXXe1Aw44wO68884mlhJAR/3oRz+y66+/3g4//HB7/vnnrU+fPmZmduKJJ9qkSZPsj3/8o803X7dNQAX0OBMnTrQ+ffrwQ7hu7oILLrCRI0faD37wA7vwwgsrk0qceOKJdu2119pnPtNjfkLSYxx22GF23HHHWZ8+feyII47gx3DoEXpML/WWW26xnXbaKf0Qzsxs6623tlVXXdVGjRrVxJKhEeb+3ws//elPK/9+ww03WK9evexXv/pVk0qGRjr66KPtoYcesptuusl+97vf2SGHHGLLL7+8Pffcc7b22ms3u3ios969e7f5f6Z87WtfM7P/psZGz7HUUkuZmTFI6+YeeeQR23HHHW3llVe2+++/3xZbbLFmFwlAB+2000624oortvnZF7/4Rdtwww07uURoloUWWsg+//nP24wZM2zixInNLg6AOqIPB3QvH3zwgZ133nm26qqrtjkT4M4772z77bef3XXXXfb00083oYQA6uUzn/mM/eY3v7GxY8fa6aefbmZmzzzzjF166aX2ox/9yNZZZ50mlxBAvfTq1cuuuuoqmzVrVkp1P3LkyGYXC3X2wQcf2FlnnWWrr766nX/++W1mV9pnn31so402akLp0EhLLrlk+lE70FP0iB/Dvf322zZx4sQ2v0jZaKON7Nlnn21CqdBIX/7yl+3www+3s846y/7617+amdn48ePtyCOPtK233toOPfTQJpcQjTK3k+5j9BwTJkwwM7PFF1+8ySVBo3z88cf23nvv2XvvvWfjx4+3Bx980E4++WRbeeWVbdNNN2128dAgjz32mO2www62wgor2AMPPMAz3gPosz73v5kzZza7WKizPfbYw8aOHWt//vOfK//+xhtv2JNPPml77rlnk0qGZnj99detV69ezOgMdCP04XqWtvpv7733ns2aNavZRUMdPfroozZ16lT71re+Ff4Pafvuu6+Zmd1+++2dWTQADbDxxhvbYYcdZuedd549//zzdsghh6TMHAC6j2uvvdY233xzW3DBBe3aa6+1a6+91rbYYotmFwt19uijj9qUKVPsW9/6FjPyA+j2en3yySefNLsQjfaXv/zFPv/5z9s111xj++yzT+WzESNG2HnnnWdz5syxBRdcsEklRCPMnj3b1l13XVtwwQXtmWeesd12280eeeQRe/755yszBKL7+PnPf24XXXSRnXfeeXbHHXfYN77xDbv33nvtvvvus1GjRjE7XA/xla98xZ5++ml74403+CK1Gxo+fLiNHj36U/++xhpr2J133mkrrLBCE0qFRho+fLg9//zz9tFHH9lyyy1nDz30kC2xxBLNLhYaLHrW99tvP/6v1G5m+vTpNnjwYDviiCNSqnszs/POO8+OO+44e/311+m7d0PDhw+3d9991x555BEzM5s8ebJdeeWVdt5559mOO+5od9xxR5NLCKCj6MP1PFH/zczskEMOsV//+tedXCI0ys9//nP7wQ9+YLfeeqvtuuuubS4zdepUW3TRRe3rX/+63XLLLZ1bQDTU8OHD7b333rMXXnih2UVBJ5o+fbqtscYaNmfOHJsyZYr98Y9/tG233bbZxQJQZ/vvv7/97ne/439G7cZ+8Ytf2FFHHZXtx6H7O+KII+ySSy6xHvAzIfRwPSKX2AcffGBm1uaP3RZaaKG0DD+G61769u1rI0eOtC222MK22GILe/rpp+3KK6/ky7RubOONN7a//vWvNmjQILvjjjts4YUXtl/84hf21FNP2bLLLtvs4qETnHnmmXb//ffbpZdeyg/hurFhw4bZ5ZdfbmZm//73v+2ll16yc88917bffnt75JFH+JKtG5o1a5Z9+OGHtuSSS9qAAQOaXRx0En3W5xo6dGiTSoNGGTBggG2//fY2atQoO++889KsvjfddJNtvPHG9N27sRdffPFTbfYuu+xiV155ZZNKBKDe6MP1PG3138zMlllmmSaUBo0yY8YMMzPr379/uMzcz+YuC6C1DRgwwC666CLbfffdbY899uCHcADQoqZPn25m+X4cAHQXPeLHcHPzH3/44Yef+mzOnDmVZdC9bLrppnbYYYfZJZdcYttuu60deOCBzS4SGugLX/hCu/4d3ctNN91kJ510kh100EF22GGHNbs4aKB+/frZ1ltvnf7ebrvtbLPNNrMNN9zQzj77bLvggguaWDo0wsorr2z77ruvHXfccbbXXnvZzTffzDTuPYB/1tF97bHHHnbbbbfZE088YZtssom9+uqr9swzz9hFF13U7KKhgeb+YOI///mPvfrqq3bGGWfYpEmT0v+wBqD10Yfreei/9QwlP3Sb+9ngwYM7pUwAGu/zn/+8mZltuOGGTS4JAKBWc/8nJf6HBQA9wXzNLkBnGDJkiJmZjR8//lOfjR8/3hZddFFmheumPvzwQ3v44YfNzOzVV1+12bNnN7dA6DQjR4604cOHN7sY6CT33Xef7bvvvrbjjjuSeqWH2mCDDWyRRRaxP/3pT80uChpkxIgRNmLECLv11lvtu9/9LlN4A93IzjvvbH379rVRo0aZmdmoUaNsvvnms29+85tNLhkaae4PJrbZZhs77LDD7K677rKnn37afvzjHze7aADqiD4c0P2sueaaZmb23HPPhcvM/WzFFVfslDIBAABg3lZffXUzM3v++eebXBIAaLwe8WO4pZde2pZYYgn7y1/+8qnPnn76aVtvvfU6v1DoFCeffLKNGTPGzj//fBs7dqwdf/zxzS4SgDp76qmn7Gtf+5ptuOGGNmrUKPvMZ3rEpKdow8cff2wzZ85sdjHQQOecc4595zvfsauuusqOOeaYZhcHQJ3069fPdtppJ7v55pvtP//5j9100022+eabkxa3h1lnnXVs7733tssuu8zefPPNZhcHQB3RhwO6l0033dQGDhxoN9xwg3388cdtLnPNNdeYmfE/NwAAAHQhm222mQ0aNMhuvPHGsB8HAN1Fj/gxnJnZbrvtZnfccYe99dZb6d8eeOABe/nllxmUd1NPPfWUnX/++faDH/zAfvSjH9mxxx5rF198sY0ePbrZRQNQJ2PGjLEdd9zRhg0bZnfccQcpr3uwhx56yGbOnGnrrrtus4uCBrvsssvsG9/4hl144YV2+umnN7s4AOpkjz32sHfeeceuuOIK+/vf/2577LFHs4uEJhgxYoR99NFHduGFFza7KGig8ePH24svvmgfffRRs4uCTkQfDug++vbtayNGjLCXXnrJTjzxxE99fuedd9rIkSNt5513trXXXrsJJQQAAEBb+vbta8cdd5yNGTPGjjvuuDZn7r7uuuvs6aefbkLpAKC+esz0OT/+8Y/t5ptvti233NKOOuoomzlzpp133nm29tpr2wEHHNDs4qHO5syZY/vtt5+tssoqdsYZZ5iZ2amnnmq33367HXDAAfb8889bv379mlxKAB0xY8YM23bbbW3q1Kl27LHH2p133ln5fKWVVrIvfvGLTSodGmnatGl23XXXmZnZv//9b3vppZfsV7/6lfXp04cZQHuA+eabz66//nqbNm2a/eQnP7FFF13UDj/88GYXC0AH7bDDDta/f3875phjbP7557fddtut2UVCE6y55pq2ww472BVXXGE/+clPbLHFFmt2kdAAJ5xwgl199dU2duxYGzZsWLOLg05CH65n0LGat/fee3dyadBII0aMsL/97W92zjnn2BNPPGG77bab9enTxx599FG77rrr7LOf/ayNHDmy2cVEg0yaNKnNHzavsMIK9u1vf7sJJQLQCCNHjrQDDjjArrrqKtt///2bXRwAdXLsscfa//3f/9kFF1xgDz30kH3jG9+wpZZayiZMmGC33XabPf300/b44483u5ioszfeeMOuvfZaM7OUTXFuf2755Ze3ffbZp2llAxqlx/wYbtlll7XRo0fb0Ucfbccff7z17t3bdtxxR7vgggtswQUXbHbxUGc//vGP7ZVXXrHHH3/cFlpoITMz6927t1199dW28cYb27HHHmuXXnppk0sJoCMmT56cZvts6wdQ++23Hz+G66bGjRuXOua9evWyQYMG2Ze+9CU7+eSTSX3eQ/Tu3dtuvfVW23rrre3II4+0gQMH2re+9a1mFwtAByy00EK2yy672PXXX29bb721DR48uNlFQpPM/Z8cfvnLX9opp5zS7OIAqCP6cN2fjtU8fgzXvcw///z229/+1nbYYQe7/PLL7aSTTrIZM2aYmdnWW29td955p/Xu3bvJpUSjTJw40X7yk5986t+32morfgwHdCMzZ840M7MhQ4Y0uSQA6mm++eaza665xr761a/ab37zGzv//PNt+vTptsQSS9gWW2xh5557Lt+tdUNjx479VP9t7t9f+tKX+DEcuqVen7Q1/yUAAAAAAAAAAECBjz76yHbeeWd74IEH7Pbbb7ftttuu2UUCAHTA7rvvbq+//jrpEgEAQEvix3AAAAAAAAAAAKBDZs2aZcOHD7cXX3zRRo8ebeuvv36ziwQAqMEnn3xiSy65pF133XW2zTbbNLs4AAAA7caP4QAAAAAAAAAAAAAAAAAALW++ZhcAAAAAAAAAAAAAAAAAAICO4sdwAAAAAAAAAAAAAAAAAICWx4/hAAAAAAAAAAAAAAAAAAAtjx/DAQAAAAAAAAAAAAAAAABaHj+GAwAAAAAAAAAAAAAAAAC0vM+ULvjJJ5+kuFevXkXrfPTRRyleYIEFKp/NmTPn/xXiM59pMy6l+2lrX235z3/+U7S9BRdcsN3lycmdk8iHH37YsPLUw7///e8Uzzff//t9pd4zOf/6178qf/fp06fN5fSa6X7M4nOUu2/1Wnz88ccpXmihhcKyfvDBB23ux5dHtzf//POH29Nzp8tpWfXY/H4BoL207vP1dO/evVOs9VMtbbPWg2ZxXVi6H20DtI70dbvWmXo8fjktn9bhupzvK/i6PtLRc1dv2s7qOTGrHqPeD3q99Hj8Z6V9wq7A9xfn0v6YP1ZdR/sn/tnR85A739G2S/uEpXL9EC279sdz/Zpo/dxzFT3zuk+zar8r2nbuWcw9bzNmzEhx//79i9bRfc2aNavN9b3Zs2enuG/fvikurQfrzfettRx6vLXcd3qsZtXjVbl+e6SWdWqRO4Zaxrw5jTwmf38pLbvuV5+/3Jin3up9Xuu57dJxW6SWdxE9mV4v3+aWnruoT6jb9u20XtuOtr+Mz9FZfD0fjVm0bvd9z+gdXSP78LlnMWoLfd9FjyN6t1jvdjrXHjSyX+L37fu9UT0Vld2sWt7cuC4aq+q7z+gdrd9e6bg3GpP57eX2q2q5rzurzwkAJaLvterR54z63r7u08+iMvj911L/lrYvKjfujcZvuo7vY+g4uJXeaQIAup5oDJlrI6PfJzVyXJL7vkqPQcvtx3fRNqLvRdqj5LvfWr+rNWNmOAAAAAAAAAAAAAAAAABAN9Drk8Lpu0p/6d+VZzErnamj3tsrPSd6jqMZHJpl5syZlb/1152lv77U49OZNhZeeOHKciWz9eT+D/zS/8Ov9P9grOc9nZtJJipPs2YVAdA91fv/6lMdbWdz/6e6/t+Duu3S/3Pei/6vjVpmzfH1dNSO5ep21ax6Pmo/S2eGy83oUMt51Wuu19XPLKb70diXR8ta+n/qRP0IXwZdT8varJkGcn0h/Uz/zx3tj/n+StRHqcds0dGzGM1a6JdTtczY15H/q6gt0f9NZdZ5fXp/THr+o/+7yl8XPV9a7tLZmdtTvra27Z9f/UzXL21rdHv+vo3u6XrU042cATKnlvY4es799crNzhqJzkOzZsisZSYb3xa2d/16K627Sme+q6Wdjv7PTb+90lkfGilq60tnSeppLrroohT/4Ac/aFo5UKV1pj7Pub5L1B6UzsRW+h4uajNz9U6uD55rt+fyx13aNtc780k95LKXdLRvGvXp/LbrOXOgP55otkBfno6+f9Vt59rJaIYBf9zMGPRpnTXDpKKtRneQa3ejmT5rySplVp41qUT0LtasWu7ouzmz6jMcHbdv60r7IiX9If+9ZvQOEQCAeqml/fVj6qj9rPfvh0rfIZe8S/XHoOcheref217pd1zzGjMzMxwAAAAAAAAAAAAAAAAAoOXxYzgAAAAAAAAAAAAAAAAAQMvjx3AAAAAAAAAAAAAAAAAAgJbX6xNN2Fqjjuae11zvml8+pyQ3bSNEx9qe3LQlNK/u/PPP3+HtdbQMer7NzBZccMF5rj9nzpzK3wsttFCK9Tx++OGH4XIlZcvR/dR6n0TnIXcOdL+5/M36md5Dupw/1s6834GupDR3Ocr5ul3roY6eY5/3ParjtK3w9X9J/8J3Y2rph0S0f2JWbY+1rffnMaqndXt+mXqW28v1UaL+hq4za9asyjr9+/dPcS39sY4+y/6aR/1If06j+yl3n0XXzJehpO/n7xPddp8+fea5fnvotv2zqEr6czm5vl4pPZdRWWfMmFH5+5133kmx9iPffvvtynKvv/56iidNmpTiyZMnp7hfv36Vdc4555yCUsdyx9NZfXp9xszKnjN/T+f6r6pkDJS7T/S5yJ07vVdrqUNyz3l0DLly6zq6vUbW5Tml7VA96PnP1bkdVTq+jtqA3Hg6GoOVvovI3U+N7K/m2txov7nzoPe4Hnuurvrggw9SnGu7SvoHnXnfRnxdE9VDen58/7D0vunKDj/88MrfV1xxRYovvvjiFB988MGdVqaO0nIPHTo0xV//+tebUZxiM2fOTPHCCy/c7vVrHRtFdUhU5/t9aT2tz0iuPqmlbs+J+pF+P9G2dX3/Hq6rPOe1vH/PraP9aO1raR3gz9+gQYNSPGzYsBTrOVpttdUq60Tj6FJ6H+aOW9sV30aVvGfXNq6tbQCt6Kyzzkrx4MGDU3zQQQc1ozg9VukYvbT9y/XJdRva39d3H6V1cTTubevv9m4vVwatszXOja+6wvepAIDuJ/fdSkl76seWHW2jSttSHQfmvpdU9fh9Uy1q+Y1Ve9p9ZoYDAAAAAAAAAAAAAAAAALQ8fgwHAAAAAAAAAAAAAAAAAGh5dUmTGsmlsoxScdVjul3UR2nqOp2GPkpNY1a9zrWmSohEU0hrWi1/DNFU07lUKbqfKO2rWXn6NQBVmsbupz/9aeWzX//61ynWOkTTefi0FppaRpe77LLLKst19XQ5nUXrK53CP5dKMap/fb0YtRW1yLVPuT6Fij7T4/Htkd53taTu6Qpyqb2idIX+PJSmDI/229HzlTsG7Xv4cus117oil2ZBr3lpivbSlHuN7B9Eqe/M4n5WaVp3PSdXX311ZTlNP/r++++n+OWXX06xr6fffffdNtfXNGETJkxos8xm1ePxfbioTtJ1/PnYdtttU3zjjTemuJY0SY1M4+zVMp24Kp2y3Z9jXa/02Y7qA61bfHm0rtHlfLoZbROie6M0XXSurukK/Xs9dv/MRsersT/Hpc9IlEYud/2j9Ga5lOO6vdJ7uqtdl3qnSe0oTYdnVi1fNH41q15zrcNrSeGo6pFutCukQ2rVPqFey759+1Y+0/th6aWXTvFbb73V+ILV6LTTTqv8ffLJJ6dYr8uDDz5YWW6zzTZrbMHqSO/36N2Ur9v1udflZs+eXVku6ufknqsoxWb0754eg6+ftDxRGfw6uq/cq269v6M6JLftrqi0z/nNb36z8ree54EDB6b4yiuvTLG/V6L1tR3/61//WllurbXWSnFpO6njGe0HlK7j+0Ylqbh9v1LXaVbKoM7SFfpQqI8DDzyw8reOabWeu+GGG1K8yy67NL5gnWz8+PEpHjJkSBNL8l/1fjdQSx8495xrv1Dru3q0f77PP1fuHbLW57l3MdG4t6PvRwAAaIt/L17Sxvj3nVH6b98Wlmzbl0f31dF3krl3g1Hfo5ZxuKfHrev4sZr2I+bVr6InAAAAAAAAAAAAAAAAAABoefwYDgAAAAAAAAAAAAAAAADQ8uqSJlWn3YtSqjQyTVAt0xLWm06h76de1+kC9Vz5c1CaVitapzOPO0p7oFMq+2PQ85JLY6dpsfr3719Unii1Wy1pSnLpEPT4dIrm3Dp6PH5a51pSzTHNM7oDfS6OPPLIFI8cOTJcJ0rflEuRp7QuXnzxxSufaZonLUMrpc2pBz2vUYpoPwWuXhc9/37631pSDEbqnRKrs+rVZqXRyqUEbVZKsUjJtdAU6GZm/fr1m+c6XtQfy6UD1OV83yXq10bPlFm171DP58OsWu5c2ik9D9pPy6VP/P3vf5/iPfbYo7Kc3l96v9dhuBHS4/EpWKN0SHrciyyySOWzO+64I8W5NiBK15x7zhuZPjGX8kSvZ+l4I+rzep1Vr9Vy7vRY9fz4+1ufe+2f+HsjSjWXEz1j9ZCbUr6Wuj0qaz1SAETHrtcllya1kTp6jfw0/Xp+6n3NS9P9Rv1kXxfXcp+U1g31VMs96NMx6bUg/dt/TZ8+PcWaHtGser7WX3/9FD/55JMNL1d77LPPPim+7rrrKp9FY8fVV1+9styYMWMaVLra5FJgR/e+Hp9/XvQ8+Ho2ovuN6hO/bZUbq0Vtc27btYzVcqlaNe2npgiO/r0z5PpTJSngPF1u7bXXTvELL7wQrqP9K9+2qSgdjd5fuXpb+1fjxo2rLBed99y1KU3vGZ3H3P3alVOfo3aN7J93BWeffXbl75/85Ccp1mPXNOi33XZbZZ0NN9ywMYVrsD/84Q8p1nSxkydPbkZx6q6j7y5z9WVH67vSskXtsx/ban1c2j7rNnQ/nd2mAwC6F21TfBtZkjq0kXLvX7Vd1Nj3f19//fUUr7jiiu0uQ65/EX3HnOtr6PnW9UvfxbeFX9IAAAAAAAAAAAAAAAAAAFoeP4YDAAAAAAAAAAAAAAAAALS8mtKklqY9qce005qqRtPY5bZdMi1vLq1lqdKp2COaXslvr7NSjpTKTVUcLeen1ddznJsuOZfOLdp/aRqzWkTXOXefRSkOcs9OPVO9Al3dIYcckmJNS6r1xuDBgyvrDBgwIMXjx49Pca490GdJp1X3tH3R/dxyyy0p3njjjcP1W5XvAui5rKXuidrsWpcrac99+xSlh/SpNYcMGZLi0jR/taQDjLpZzUrR5fseOr1w9Cz5VGN67LkUOtqGR+ln/PrRec2dryidw5QpUyrL6b2hfZJcSnY9J1puf99FfQ+9b+vR96xF7jmP0sb51EZRak3fH9PzEj2zuZROEX+ull122RRrnb3CCitUltN2RFMyLb/88m0uY2a2ww47pLh0+m097ty9qtei3lOn1zt9dKR0HJhTUpf6+zZKOZw71tI6u7RNqiV9WkfHi60kl1I9uma51H7RcrWcx1xfQe+NXN1ecgz+70amXvdK7mP//OrxNbLeKE2bFKVP7Aop3bvjs6zpQddcc81wuS222CLFo0ePbmiZIppK8fDDD0/x7bffXrT+0KFDU3zEEUdUPjvhhBM6WLrG8X1HfX5qGavl7uOozcw9v/qZjjH0fabfTz1TkebqbD0eXwYdL0T9Uj/+aXS/vTTlqV5DvT8mTpxYWUffXei7k9y50Piwww5L8bRp0yrrvP32221ue+rUqSl+7bXXwmPQY910000ryz366KMpriWljt4Tvs3T9aJ63I+Vtf3h3Sxalb5/vfLKK1Osz8s222xTWeeee+5pfMHq4MILL6z8/aMf/SjF2sboGP/mm29ufMH+f7kxun4W9YF9fRdtz7dZ0buv0rFXR+X6LxrXu4+v7ZWOh3LfI3bmeA1olAceeCDFBx10UIr9uwqtQ95///0U77nnnim+4oorGlBCoPvwz5WOK6LvRXI/w6p32nOl7Z2Ojfw4ul+/finW+mTzzTevLFfyHUA9vjeI2unS3ym1hdYeAAAAAAAAAAAAAAAAANDy+DEcAAAAAAAAAAAAAAAAAKDl8WM4AAAAAAAAAAAAAAAAAEDLK07WqrlYfY7XKD9tLblgPc3vrt58880U//3vf698tuKKK6a4d+/eKe7fv3+KBw8e3OGyRbl4P/roo8rfCyywQJvLLbTQQpW/NQ+umjNnTrhOZ/HHFOXi1XPSp0+fymd6fBr7fMl6jPpZLndytFyUW7g9cjmX5/K5iqNr7p8JLV/0vORyu9fjGQM6w7vvvlv5+7XXXkux3tPLLrtsiv/whz9U1vnc5z5Xt/Lst99+lb+vueaaNpf79re/neI77rij8tkaa6xRt/J0FVEe+Vxd88EHH6R4wQUXTPGf/vSnynKnnXZaiqdNm5bimTNnpljbOzOz2bNnp/hf//pXm+v4PPRaBm27dtxxx8pyZ5xxRoq1r6D34yqrrFJZp7TOjdpt3XZ7ctp3lF5XPVZPj0/Xido0s+px3H333ZXP9Nrsuuuuba7vy6PXObou/txpuadMmZLi888/v7LcSiutlOKDDjqozfL49jw6J75voPea3oMq+vdGiPrmZvFx5J557UPpeXz11VfDMnznO99J8cYbb5ziAQMGVJZbZpllUjxkyJAU9+3bN8XahzernsvSvl50Tny9k7vfle5X70m9F/y2fJ+unvTY/X702kbH58ch0bn090b0zGoZdBmz6vXT+lyvuafbi863Wfn1U37MEsmVL1IyjqiV3rv+uujfuXuyFlF9rPeMv3/0+uXqp0huuVrGe6XnIdpebp+NvOb6LPv96HuT0v5GaV8kek+RO9/RfVfa1tSi9N6q5Z7R7fm+Qmf26epp/Pjx4Wd6bZZeeunOKE7FuHHjKn/vtttuKX722WdTrO3Jhx9+WFlnrbXWSvHRRx+d4gMOOKBu5WwEvT9zfcfS+z1azvcV9DktbTf0+dHloj6SWXlbquWL+jG+btLPojGhF9UB9Wgv2yNXF2mdo7Ee46xZsyrrTJgwoc1t+es+aNCgFOt4Xd+X+HW0v6f3lL6nX3/99SvrTJ48OcVav/j3+UcccUSKf/7zn6c4aoc8PY/+3tOyRuMh/87dv2uop1raolr6UI0sD1rDueeem+L3338/xaNGjUqxvqMzq76Lq2UMVG867jnppJNSfMEFF4TrbLvttim++eabG1Oweci1u1q/aH0+ffr0FPu+ctTn9P8etWFanlrGAb7e0WPQ4/P9l6gO175bre/LdL96r+b6ItRxaEWPPvpo5W/tt6255pptLtevX7/KOvpcLLbYYinW9mD//fevrDNy5Miaygt0J/69tioZN5a+c/djD+0HRO/5/LZ1XKjtoo7h/Hee2r5/+ctfTvGLL75YWW611VZrc7/aFpd+f5o71uj7E9+et2f8QssPAAAAAAAAAAAAAAAAAGh5/BgOAAAAAAAAAAAAAAAAANDyinMs5qbO1Sn0Sqe3LU218dxzz6X4gQceaPPfr7vuuso6Or1elDLTT+urqZx+85vfpNhPf5hLLzZXrdPpR9P4RWlDzRqbhkX549Zzqddc0wzlylqaxiE6J7nUJKVTeZdOoRiliNB1fHk6iunp0R2MHTs2xYcffnjls/vvvz/Feo9rfV7PtKje1VdfXfl70qRJKdZUj5q+TeNWpvWVr6e13c6lX1Na7z/++OMpPuywwyrL/eMf/2h/YWvgUyTNdfvtt1f+/uMf/5hiPQ9f+tKXUnzJJZdU1tGpgJVvA7TNjKbmL50euR5y6RM7So/plVdeqXym6Xk0Taq2q7m0O9F+/LnTe/WKK65I8RJLLFFZLkqLVXpOcteolhRpjUxzkxP1z7U8/jnSdXzK0sghhxySYk2VlOvDRak1fZmjeix3LaP9+G3r/VmaLljllmvkddaU1bm0nyX9Wi/XL42e2Sjti1n1+mlqR70u/jmPnrHc+db91DI+82WIyldahnqnUtQxYi4FXOkU9ZHSa6H/7tMPR+PZXPqaUlEbV8vzlmubtV70adQ6S2na8+jYO5JSYC69p3Pr6HOh90PJ+xSz6vn2z5je73pMeq/79zil9V3JM9uqaVG9t956K8X+ntHzMHTo0E4pzz333JNifT9n9um0qXPp/bTppptWPjv99NNTPHz48DqUsHPk3jOV3Hu5PpzK1ZHRe1T/XGl5oraw9B2mL7duL0qNWpoqvfSZLXkX2Rn8OdPyR6nip06dWlknuo98+tLzzjsvxZoSR/k2PbLccsul+JZbbql8ps+g9hH9OxZN7RWlYvfraAqw6PsAr/T6drQPlVPLPdbIsQTvnruvRRZZJMWnnnpqirVtfeaZZyrr6Ps8//60M7z22muVv88888wUX3XVVeF6+g5o7bXXrn/B2in3XVhUvwwYMKBo29oml/avS5WOYbXO1XcQpe1zrt6Jjs/3jaKU7fp+xKdiy70vQX1suOGGKX777bdTrPeTjkXMOve9aKvQ30Dcdtttlc9OOeWUFK+66qopXnzxxdu9n9133z3Fmj7VzGyPPfZI8U033dTubQPdgbbZtbxPyo0pcilGS9r63Hv6qA0fPHhw5W/9Tk/XnzJlSlTs8Dz4sWz0mzG/vv6up7Rf057vORnpAAAAAAAAAAAAAAAAAABaHj+GAwAAAAAAAAAAAAAAAAC0vLrP9106fV00hd4TTzxR+XvEiBEp1unSc3Tqvyh9pZ8+7/LLL0/x6NGjU+ynzT3wwANTrKkbcuk4OypKZ9SZclM/lqTbmtc2lE6Jq9MY6xSRuSmaS69FNIVibirnKP2eL8+0adNSrOnE/DmIzolOf+nT8DRymn6gnk444YQUa9obs+pztdJKK6V4yJAhjS9YGwYOHJhifca0Dtp///0r69x3330p7qz0QfWQqz+j9Fu5dkg/mzVrVop9WlSt2zuaqjPXzmu7rdfSp8zUadq1bteU7Mcdd1xlnVtvvTXFejy1pMtq1vTvfr967FFKJH98pe2Q3g+1pBOP0p77tlPT20+fPj3FOmV8W+vNpefE9wGi9Ky59EWRzkx1n3veov3qv0d9O7NqCiSdst+sWj+88847Kc6lvY7Sb+XSENZyXTSlktZvfuwSjWVqSVXmNTI1rpbPb7tk/ODTQ+o2orrBLxfddz6dVdRXz6XGrUWURtRfu+iz3NilZLxiVv/U1BF/jaP9allzz0t0/c2q6dL0Ouk6/hrredHznbu3IrlzqmXI1Q211DtR3VBannrQMvjnSlMOR6lMfaq70hRBuo1a0qjpeS3tD+TSmpbUD34d7ZPoZ/5e1eegNP1UI9MhN1Kur6DH4VPl1NO1116b4iOOOCLF2p/ztD7ZaqutUnzRRRdVltN0Qa0keudkVr13tS7Vc1LafvqUp1ovRu2nb2u0rFqGXFq4GTNmpFjvs/fee6+y3Pvvv5/iRRddNMXLLLNMiv1zruXR+k7rRy86j76+1DqgEekktX0urUduvvnmFO+zzz6Vz/R6brzxxim+9NJLK8tpHz2qy/w1jOoO/Xeftvi3v/1tivfaa6821zf7dMqetrbt7/Eodb1vb3L9gkgubRE6T2eOo7u71VdfPcX77bdfih9//PHKcprqWJ8dbbcb6bHHHqv8feWVV7a53Iorrlj5+6STTkrxAQccUP+CtVPuXtV6NmpPfXsQvbP1bXrJuMWnDtX6s7Qd6mi60VydHR2D9unN4rSy2pehzmgMTUWc68f596xzrbnmmpW/x4wZU7/CtbAXX3wxxdp/0t8lmH36/NWLjq/MqvXBDjvskGJtJ8xIP9xV6bOodaGmUMe8Re8azeL3ZaXvk7QP4N9JRu9JdUytvz8xK3sf4L8nVVrucePGVT6Lxn659+LRe9bSPlJu3Nae92/MDAcAAAAAAAAAAAAAAAAAaHn8GA4AAAAAAAAAAAAAAAAA0PL4MRwAAAAAAAAAAAAAAAAAoOV9Zt6LtE9Jzlizat7YP/zhDyk+6aSTKsu98MILba6j21t99dUr62hOXM23q+uMHz++so7mm3/11VdT7PPVn3HGGSlefPHFU7zbbrul2Oep9Tly22uBBRYIy9OenLgdEeUmNvt0mebyOX/nzJmTYs2R7PPG62fRNffnVMuneZl123oezarnTo/BLxeVLXd/a85t/UzLZhY/L5pHOXfu/faArmS99dZL8X333Vf5bOjQoSkePXp0ihdddNGGl6stN9xwQ4rfeuutFD/66KMpfvnllyvraP70VqL1oq+noxz3s2fPbvPfzar1cZ8+fcLltC5ba621UnzzzTenuF+/fpV19G+tLwcNGmQR3Y+Wzd+D+++/f4onTJjQ5vq+bo9y2ft6Wo89agM6s/7OtZ9aDv1Mjyk6bm/AgAGVv7VvpdvQdjb3HPXt2zfF2k5fc801leXGjBmT4ssuuyzFes/k6LFq++u3Ed1bnpY1d+5Kz2tH+f1E90Npf1XraX/va7978uTJbZbB912j85+7B/VvvYf9NddrsfDCC/tDMbNP34PRM5Hrg+s51XJrv9F/Vu8+vNaXubJGz4W/ltH9kOvL6nnQferYzKx6zvWaa93gy6PtkI4pFltsscpy0XMVlc2XQe9hX25VWh90dBxYyo+nov2Wlke358+X3gPR+fbr6DXT9fV8+zFY9Gz766LXQsut6+faab3+uWcn2l7umWgkX6fpfqPxrPbTvNJj6mjblRsbR3V7Lfy9HrUBOVqHd4VrXm+vv/56in3/R6/TkCFD6rbPiy66qPL3CSeckOLcew+13377pfiCCy5Isb6DaWW5PpMqfS6jfqnvo+hy2k7rs/TXv/61ss5OO+3U5joa+/ZJ7y19p+rfA2i7sd1226X45z//eYr9fau0rYjeWZrF9aUfB+b2VQ9aRl9/6bWeOnVqil977bUU++dHr/WGG26Y4nXXXbeyXO6d6Vy5/lBpP+Cb3/xmirXcP/nJTyrL/fOf/0zxVVddlWJ97nPvbHNli9pxjfW+M6ut7ag3vTc66zuArqazxs09zbBhw1K88sorVz4bO3Zsiq+77roUr7jiiik+9dRT61qexx9/PMU33nhj5TO9BzbddNMUjxgxorLczjvvXNcyNVJufDOXb0OjMahv0yO5Zyl691Va72hd5dukkj5Lrmy1vJ/U5Zr1fWp39PnPfz7FWk/o+99Sjz32WF3K1N28//77KX7uuedSvOaaazahNGbDhw9PsT5XX//61yvL3X333Z1VJGTo95pm1d/b6JjgyCOP7LQydQe19EVLxyy5Nlz7Bzo+LW33I6XveN59993wMx3za3n89yx6HvQ8+uX0e0ClfYgPPvig8pm+45zXNeKXNAAAAAAAAAAAAAAAAACAlseP4QAAAAAAAAAAAAAAAAAALa/ueVuidBa5lCyauuwf//hHuFw0JfKJJ55YWW777befZzm9Aw88MMU6Fbs3ceLEFF944YUpXnLJJVO81VZbhevnpjeP0lbpNIB+nZIp7evBX1ctq+43N+2xHpNuz08FrdPS67b12DWljl8u+vdc2g3ddi6NTjQtc24Kxty9X5LKya+v56fRqRqAjjj++ONTPH369Mpnhx9+eIqblRq1vXJpNlqJlrt0anhNv+en6Y+2katztV5bZZVV2l0enRLXp/zS/WpavS9/+cuV5e68884Uf+1rX0uxpozS2KyaGmj99ddvc59m1bYwSt3t759GtuG5Nk7LOm3atBQPHDiw3fvx6QonTZqU4uh58dM6R23cAw88kOJbbrmlss4dd9yR4tKUUToVc+7c51IWqah/0Kx6Qo/PX3M9r6X9SN3G4MGDU5xLX/rGG28UlTVKhajHkEutqv1IX56S1HW5qcVzafFUdG9oHWQWT/ldD7l0sUrPkS7ny6rby6XA1u1F56G0bo/Sc5uZff/730+xtklHH310ZbkVVlihzW3n0kOq3P0QpZrLpYRpZN3eyP3ktlcyHX9pmnE9d6Vp2Pw4UOm9Vkv97fs4UUrYXH3QrFRempomSuvm78/SOk6PqXQsGqWdy6Ux0Ode78FGPkf+mkf7qqUN6Oree++9FPvUgFEq4VoceuihKdZ09u3xwx/+MMWnnXZairtCCsN6y6UY0edK79Xo/ZxZeRsctee5VCba5mpqJF1f22yzeJzkldRPuXd3paL0Lp3Vfs+l58y3ofrZ2WefneLzzjsv3N7JJ5+c4oMPPjjF/hzp37rf0vedUco+v070Ltzfn+PGjUuxpgbTujrXX1C5+0HvQy13V6xTulo6P9K2dh/bbLNNin/6059WPtO2W+sGbYM1zaqZ2QEHHNDuMvzv//5vm9t+4YUXKstpuuxzzjknxWuvvXa799mZovGjWVmb5dui6B2JHx9pvRY9p/6dQfQOt/SdUa5uj/abG19FKdtz71Si9yA+rZpuo1Xf7TeLpjP372xUybs4tE3v9/HjxzexJJ+mv4Eo7Y/Vwt8/pEvP0zbz2muvrXz2xz/+McWbbbZZp5WpO/PvkKJxXOn4rvQdvratun5pKnDdT+69ru5Tfw9lVu1v6Hsi7UP4bUfnxLe/ehzRWM33AbQ886qTaO0BAAAAAAAAAAAAAAAAAC2PH8MBAAAAAAAAAAAAAAAAAFpeQ/M56FSpfvq6008/PcW33nprinNp1XRK5BNOOCHFX/ziFztUTjOzX/3qVynWdBF33XVXZTmdDviZZ55J8bvvvlu0n9w0wVF6jdw0oI2cul+nEPZl0zLptJC5FCGl6UN0OZ0SWVOqTJ48ubLO0KFDi7ataplmv3QK+CgVnp8OM0rjmtsPqVFrp3XIL37xixSvuuqqzShOj3LmmWc2uwhZe+yxR4qfffbZFOvzO2rUqMo6yy23XOML1gC5+qVkOtrcNLoDBgwoKkOU/ttPXR+ltculuytN07feeuulWNNubrDBBil+6aWXKuvofaJTw5emX9O2xk9hXJresxaa+spPQaxl0mubS38STd+8yCKLVP726ZHnyk1hrO3k448/nuLzzz8/xffee29lHW1zS6d8Lu0/lUx17ek5jlIvNVrp8eX63UqPSdNd+XtB/546dWrRtqP+Zj36O7q9KL1HLsVWFHtRmtxmpc4rrUN0Oe0XmZm99dZbKda05z4NaUndVZqCRZ+XSy+9tPLZVVddlWJNYbXaaqtVljviiCPa3HZpehc9htw09kqPz9ftpfVGLWpJC11aD2m74etp3Vd0Lf05jspXmjpY9+PTAGmfIHoW/XWJnu1cvROdx9z93cj0Yf7c63NRmoaglrRApfexnv/S61y6nLYbpSmQI52dCrErmTBhQvhZlB49R9//7b777im+8847i9bX+1Hfz5mZffe7301xT0qT4+tsrcu0Tqql7vIpT0vaB78ffRYHDhyY4qgu9nLp43y9PVeu3ipt61V03L7ta3SfvrS9mDRpUtFymsZqqaWWCpfTaxW16f549Vzo9cilttW2Y5999kmxvlc3M/v973+f4j/96U8pHj16dIq//OUvV9bRc5e736J3EN3dmDFjKn//4Q9/SLH28Ut15XPn++5Rail8mj6XZtXvuc4999wUax209NJL17QvHdddeOGFKX755ZdT7Nuo73znOynu6qlRld539UgbGaVFy32vNWPGjBT3798/xaXjNT2G3LuTXBugZS1dJ+qzlKZ20/PdFVNgt4plllmm8ve0adPaXI60qLXzfbsrr7wyxX5M1Gyrr756im+77baG7acnjffa45577kmxvrN9/fXXU+zbc021q+MD1M63Q9qW6XhZ2y7f5uo6OobN9Vd1e9ru58bR0Tvuddddt7JO1H76Or/kuxrfH4/4dl/XK+0DtCddMzPDAQAAAAAAAAAAAAAAAABaHj+GAwAAAAAAAAAAAAAAAAC0vIbm7smludApzidOnJhiPzXefvvtl+JTTz01xcsuu2xRGXKpuJR+dv3116d46623riz39NNPt7n+jTfemOJNN9208tnyyy/f5jrNSqlSSqcczJWnNEWPHp+uk5s+X2NNwbDhhhtW1tHrotN06378+dZrrtNC3nTTTZXldPpXTRmkU0L6FA56HmbOnNnmPs2qx67r6H3rp36sJZ1NT7X55ptX/n7yySdTvNFGG6X4xRdfrCyXSyOB7um5555LsT7nWm/tuOOOnVqmzuBTjWk9VJpaRuu/3FS5WpfNmjWrzWV8qqtoWl/9d19OnVq4ND2dpn/SOjZKz2NWPk1/dAyd2c7nUohpyoRc+ksVtfW56Y1V7th1+u4RI0akWNPk+OuSS3mpOpqKNpf2PLq/cqn0Gjntu25b05aZVfvn2i/J9T10e9oH13vGrPpsR+kTvFzajejfa0lFq9csSs3hP8ulC47WUbmp0xvZn9N2zKx6/bRMmqLm7LPPrqyj/W6tV//nf/6nslw0Tbvy9350nfTffdod3fauu+6a4igtqln1fNeSotQ/o9qn11QrufTMjUwXUlqHROc7Vyfl2vMo9bY+I76eLrn3/X2ry+kx+PssGmPmjiGqD3LPZZRK3NchjUy7GaUY8p9FKZR826XnsrSN1Ouk7YkvT5RON5emLnrGfLlrSaPd0T5AI1MeN8uUKVNSnDsmnx5prnHjxlX+3nfffVP80EMPtbs8o0aNSvFuu+3W7vW7i9y9qn9HYyP/XOly+vyWpvrU53fAgAGVz7TvmHv3Fq2Te5ZrSakW1eH+nOg2onQsXiNSo6rSPufkyZNTnOvPLrHEEikurfN0e9r3y4n6WrlxtI69/bHq9Xj22WdT/Nprr6V4m222Cbet+/VlqOUadrTt6IpuvfXWFNeSJrUr6y7tc1dwzDHHpFjH9Tpm3G677SrrvPDCCylec801U/zjH/+4spyOJ/U7QX3evv/971fW2XLLLYvL3pXoMfl6Okqhmqtr9DOts6dPn15ZTtvXKEVoLq2alk3bA31HYFbtF+Ta/uj7rygtW1vl64hcm9bIsVt3oO+M0Rj+u5mHH344xc1Ik5p7R4rmmjp1aorfeOONFB988MEpXm655Srr6Pcs/h0+alP6jOSeHR3zlLaFUT/X7ycaL+tYSNOmt7XfuUq/28kda2kdou1xScpU/9m8UJMBAAAAAAAAAAAAAAAAAFoeP4YDAAAAAAAAAAAAAAAAALQ8fgwHAAAAAAAAAAAAAAAAAGh5bSeZbSfNQRvlffd5dCdOnJhizQXrc88fffTRKV522WXbXbYFF1ywzTLk8tT26dMnxVdeeWXls2222SbFmm/5zjvvTPGPfvSjyjrLL798m/vR82NmNv/884dlagYtj89druc1us4fffRRuI7/TOn2opzG/pxqvuwhQ4akWHMd+5zKK6ywQooffPDBcNsl+Zv9/aSfDRgwIMUff/xxuJzuR8+Vz9es10KXw6fpM2pWPcea73qhhRbqtDKha9hggw0qf7/00kspjnKka1vVXfi86nrsvo2KaFvh881HZsyYkWKf6z1Xvrm0zvXXS+v60pz0Y8eOTbG2Y76O3WSTTeZZNrNqXa/nR+sgfz91Vt3u+2PRNdNz59suPSZtz7W9MzN77733Uhy1x6+88kplnUMOOSTFt99+e5vr+3tG+21aHn8e9Th8n6CtZcyqx6rnxN9but+ortDrn9t2Pei+9PyYVe+BqC/j7xMt69ChQ1M8a9asynJ6XrVvljs/0bOk19lfFz0mXT/XX/XnYa5c/1vPQz366fW+zkrPsS+r/q11+3777Zfifv36VdbZc889U/zcc8+l+Jlnnqks59vTtsqTaz/1mj3++OMp3nfffSvLabknTJgQbk/3q/djrk2L+uO+3AsvvHCb6+fapNK2tBZRW1PKl02fuWjMY1bWb/bP9ezZs1OsZdXn0h+Dnn8tg27LLL4uuk6ur1CLRtbfpfvNfRbVXf481HIPRec7p/QcRdv21yvqq+d09Fns6D3TFen19+2sXrNFFlkkxU888USKfT2tfbrS9yZjxoxJ8aqrrlpc9u4s1w7p+YvGC/5dm25D45kzZ1aW0+cvesc7cODAyjra19PlovrIlyE39vTrzVVan8yZMyfFuTGvlsc/Byp6T1kvuTpKz8Xbb7/d5r970XtoPS9m1TY9Guv4sVfUd9d7t7TO1PcCfj29j4YNGxZuI2rLSvv4ndmON4Mf7/t+FDAvP/vZz1J89913p9iPCzfffPMUv/zyyyl+9tlnK8u9//77Kdb6+MQTT0zx6aefXnuBu5Cobcwtl3s3qG231t/+XVxH3+1G7+/8fqL1c+9lIrlxtLY7uXd20fq+P1XLWAL/1bdv3xRzHuvDn0f/7rizdfd+USvT97SltM1dcskl61iansuPwUrGQL4tLv3+spbxVckzPHjw4Mrf2r7rPvW3Np6eB10n951paTl1e9FvhNqLmg0AAAAAAAAAAAAAAAAA0PL4MRwAAAAAAAAAAAAAAAAAoOXVlOvBT92p09RFKXH8lHc6PaOmRvVT/WlKhoifljBK7VU6xaeWYa211qp8tthii6VYUzDqORk0aFDRfrxapjDWKe7rneoxl2JURakEclMg672Ru35RSg1Nz2Fmtsoqq6T4f//3f1O88sorp9inf3rzzTdTrOke/P0dpVzLpVsrvX5RCptciuHumKoxomlT/P2taW4jWs+YVVN/6NTiPt0Huie9Z15//fXKZ9Ez+/zzzzeySE2RSxsWtZm5lDFRKhJfV2l6FU3NUcv0tvr85tJ1RSlKzcz+9re/pXiLLbZocx1ft1999dUpzqVW0W1Eaed8WvhGpmsuTQMTLVeaOs2nTNDrrG3pO++8k+LDDz+8ss7xxx+fYk1N/+c//znF/t6K0ozn0pKq0jRxupyvM7RMes31/vbrNDJ9ol6/0v1G963/TKdV98+v3kNaz+r5yaVnivbp9/Pqq6+mWOuxlVZaqbKc39dcep/kUsLm0olpeojSMUZp3VWLKO2YWfWa63Ohx7rccstV1tH6T+vL73//+5XlHnvssXmWx6dJ0eup12KppZZqs5y+rLnzXdJP9inkomnnS1OwqM5Mk1paN0d1Ui69Wu5+Kqkz/bNXcr/nrp0eQ25bug1/nVVpGt+SlAT+PumsdJqlqe5UZ6b6rCUFXUmaebPqcxWllfLtRpS20ZctqiNLUxi2UlqZsWPHpti3xdpPveaaa1J89tlnp3jKlCnhtqO0Sb7eiVI59mS5+lfpNdI+ia/TovvTp4+P0pzkxka+fS9RSxrn6Bhy7bTe07n0U1H/wtc7jX4Pl6s79LPp06e3uYzeA2bxOy7/rOt4Lerb+vo06lfk2hi9hno9JkyYUFkuand1/JFLBVxLKqGcRvbjOot/1n1q2vaq5buLVlJLCnn8l/YLNtxwwxTr92dm1bbj2muvTfHee+/dwNI1X67u0udKx8d+HU17rP0A30bpelGKUX9/R32OWp7zXJum1z/qE5hVxzr6rjG37ahNq2Vc39Nov0HbCX9fRPdJLpWeXpdp06bVWMLuy/+WwH9nBXTExIkTU0ya1PrwYwytF0vfaWlblnufpPvS9jNKJV5KU9ubmf3lL39J8THHHJPis846q7KcHmv0uxnfTkTfzfgxisqN5aPyzKu/0jpv6gAAAAAAAAAAAAAAAAAACPBjOAAAAAAAAAAAAAAAAABAy+v1SW6OuUAurWWpKH2T37ZOoRel3fSpxnLT63XU0ksvneIoTerkyZMr6yy66KJtbis3RW9XmHZcr4UvQ5S+NEePV6fV99NK6vSKek50Gkifik1pmqdx48alWNOimpkts8wyba5fmt4oSq1glp/mWen9rdNZahl62tTN99xzT4q32267cLm33347xYMHD06x3k86fbjZp1OczVVaDR5yyCEpvuyyy4rWQXPpNN86FXfuudKUQcsuu2xDytVMudRg0VS+USoUr7Rt0HZ61qxZKfb1rZY1SnPipxnWY9D+gW9zhw4d2uZ+VC7VqypN950793ocjUzDk0sTpOdfz7c/P1E6IZ8uS1OYv/baayneb7/9UnzqqadW1ll77bVT/OKLL6ZY2wPfnkepf3NTUJemzelo6rNcqp5GprpXPoVVLt1VCe1b5epI7f9qyhPfb9c6V9MBTJ06NcU+7bk+z0sssUSKR40aVVlus802a3MdPW7fHpTWd11Z6VhN789JkyZVPttoo41SrNdc+1xmZueff36K99xzzxTn0lXqZ1pvfPaznw3Lo2lOdJr/Wp4dXzfo/ZBLHRr1z5uVIjFKOWZWvd/1PtZ6x9/7tbQ9Ub/Bj9uj9jO3/1ya00gNrzYqcs9ONEb117wrjONL6fXLpdcukXuuunLKMX/PROP4rnwMtdL+uE9dEbV/uWdZ76FVV101xdqfy5VBUyjhv3LvpvzYZi5/f2o/MJcmPkrVoveG36e+l4vSFPv96HXW7S2yyCJhuXV7ufopGjv681jSVpeOf+pFz4Xft/Z1opSg/rzoe2lNL17a1uf6NloPRONHX55oez5dk/bxtH7429/+luIVVlihsk6U0ro0jbku59syvXcaOV7rTHo/RO9IW0l3bJ9bhU/HrO/29Fny3+HceeedKdbxendUy/0Ztds5uf5CZ41Va3mPErX1ZnF7798nRWP50r5DTzZs2LAUv/HGGynOpbuL+lq+zY3e+6+44oopfvXVV2sodffXr1+/FOu5A2qh/T5NgUy92BjRb0b8+dY6M3ov5//Wcbm+I6+3Wvohud/7RH2Pevw+qj39LGaGAwAAAAAAAAAAAAAAAAC0PH4MBwAAAAAAAAAAAAAAAABoeTWlSfWi6XZ1uu3tt9++ss6TTz6ZYp2q8Zxzzqkst++++6a4kVOSl04ZHJVBp4iN0hX4z+oxfXdnpdjKic5d6TSHfhr66Lzk1lGaClGn3PflqWV6RlU6XWTu3tKpnXX6yEamyOvqNH3e9ddfn2J/XXR6zChFXm4KTZ0u26eQ23zzzVOsqVbvvvvuFH/ve9+rrHPxxReH+0LzaPui1zlXh9ShWezSOiuNhK/vorSb6623Xop9mk29Tlq3axqdd955JyyD7jN3zaM0WDvttFNludtvvz3cRgmt831K966QVq2WeyPXxumUzVtttVWKjzvuuBR/8YtfrKwT7Teq830ZorS0ZtV6P0oFlesDRqnN/TZy02B3llx61pJ7rbQP569XtL2onfbb0P3qtvx1ifraw4cPr/z90EMPtblcbltantwzG2nWs1zv9Cc6fb6mvPXpzvQYp0+fnmJ9/kvTtubOl6Znfffdd8PlVGlfXe8BXcdPO6/L6XWuJd1wPeRSb6uO3pP++unf0bH7a6zr5Oonlav3S5Sen9x9UnLNS+/vrsCnFSqt1yK1pE/QttRffz3fpc9sLakU8F/1PkfaBmv7q2nUtD/vDRkyJMW5/n1Pkqtfovu9tE7yKW+j1Ka5Ok33q+9NcqlV9bnXNFATJkwIy9PRMUoulbgeQzPfw+XqL00dOnTo0DbX92MTTatV+qzrPaHXvR79nKjvru9rzKr3jpZbv1/w/bOoLfLv+Urbqe6uo/2rWpDKtGeIxu++Dsq9m+tufJusSsYMtdZjUSrLevf9ankHocek7W6tY6govZyeg9K0rT2Z3hvazmp6+3ro7t+51EPpdxlAiWb0+3qyaAzq21/9LBrjm1XHZ7oNrSdyfWsdW+l+fLsYjaf8GE7rJF1Oj9sfa9RXyJ2TRrzP67pvagEAAAAAAAAAAAAAAAAAKMSP4QAAAAAAAAAAAAAAAAAALY8fwwEAAAAAAAAAAAAAAAAAWl6vTwoTBWsuWM1Hm/POO++keOmllw6XW3zxxVM8adKkcDnNT5vLg1ti2rRplb8XWWSRovX+8Ic/pHjXXXdN8cILL5zio48+urLOqaeeWkMJ26Y5fs3MFlpoobptO8fnBlZ6C2m8wAILFG2j9Frm8g6PGzcuxRtssEGK33jjjRQvuuiilXU0573mRPbljvIYl+YwjvItm8X5kvFfO+ywQ4rHjx9f+WzMmDEp1nOs1yKXn1qtueaalb//8Y9/zLNs/r7VOhLN45+j6Dnt27dvZTltEzravrQS/0zUsx7q169f5e+PPvooxXottG3IPbMaa136r3/9q7KO5rzXusHTY43qhnvvvbfy9/Dhw1Ps2woVHauW1d+DjaTnwV/j3HGUiM6dmdliiy2W4l/+8pcp3nvvvYu2reWeNWtWildZZZXKck8++WSbn+l1MIuP9YMPPgiX0eundYPvPutypW17LX3rWvj+V1TH6Xno06dP5bOoL+P7zzNnzkyxngfdpz8n/jq1xa+jY4clllgixaNHj64sN2jQoBTrNctdl6hP5695dO/rsfpj02vuz3FHlfZLVenY6stf/nKK//a3v1U+02dz8uTJKdbj89vW86LPnD6/r732WmWdiRMnpljrlhzdj5bBtxul4yk9X7rtzhqPeXo/+Wte0pcprRty48BofV+eklcOfhk9xwMGDEixHw9H91OO1nda//r1o36EH9N1NbWck1K11DWdRe9VX0dH7WxXO4bOpH3mXH9Or7nWdwcccEBluYsvvnie+8yN1dR2221X+fvuu++e57a7i1x9GY2hcn0PlasPtG3UeyNqS82q98Pbb7+dYh0H1mPM08h6J3qf2ZXez02YMCHF6623XorffffdFK+00kqVdf75z3+mWNsy32eJxi2l70ijsXyuDtZyL7XUUpXldBsDBw5MsX5XUPq+xr+jKxlvlfaNWpn2Yd5///0U13tsgp5Hnxd93vr3719Z7r333uu0MnVlJWPx0ne2frmSttL3N2pp9/QYtM6t5fsvX/9G2/PHqseh28j1c7tSG9/V+XtT/9b3bdq2o2Oi759z76GBuaZPn175e+jQoSnWd/aonW+v9FmMxkm5MUUt3w+VfvdUWoZoOT+ein57UVqG3He1Ok7V+k7L49tzfVcxr/e0tPwAAAAAAAAAAAAAAAAAgJbHj+EAAAAAAAAAAAAAAAAAAC2vOCeTTs+Xm5JTp7mbMmVKiv0UdTo1np8WXeXSNbSXTvtfmhbVW2edddr8d51i8vrrr698pmlScylLSqb+91Pad1aKrdKp4UtSXc1re9EUj3p+Xnrppco622+/fYrffPPNFOemaNZzrOfOly1KU5GbilbXyU3PqM+LTt9cml6gu7vrrrtS7M/Duuuum+IXX3wxxbl0pfr8aIqlXFpUTa+r5cmldEbj6fXTdA7+udR6Vp/FGTNmNLB0rSOXhkfb6ShddHtEKXb02c6VJ0rbUpr206fK9qmX27LjjjtW/tZp3/W+82XQY9J6p1n1d64dis5/lOLSrHq8UTttVj32nXbaKcW59OFKt6fT72sqRrNqasVbbrmlzX83i++NXPqE0mtWS0q6Rk5pX9o/1Oc8dy30mPS6LLfccpXlXnnllRTrdT722GNT7PvSmvJSp2/Xfx8yZEhYtpzZs2enWO9VvTdzaTZydV9JvejPfT3HNV6u/6PXL/dsKx033XPPPSn+3Oc+V1lO++Q65jnmmGNSrKlsfXm23XbbFI8dOzbF+lyamU2dOjXFuTSpet9F6XlLU1z666Xbi86dn/I9N8boqI62KbVMkZ+jqUdz9N6K2kuz6j2g/T7/vEVpXKO0PWblqcCidE9K6xmzzk2DHonaoXqk+I7qkFya2yjlYq0pXKOyljyj7VHaF47SS3ZFUWoy/xzp8Wof+ogjjkjxySef3O795/pZus//+7//a/e2u4tc/7CkH+Gfq9JU17rf6Dn17/u0vtN6tbQejFJsmtU2/ozeqebqvty7t2bx5dB35jfeeGOKt9566xT7se3Xv/71FN96663hvqL6XvtKPr281nNRXevPub4zz6Vo0vW07ints0TXtlRPSJO68MILp3jWrFkp7sppUrUfaPbpPiOaI5fuVOsNTXnc0+TGVCUpT3PvGku25Wk77tv0Bx98MMWaenuNNdYItxf1vUvTtubSpUVj9tyxRnU2aVFr58c2Wh/z3VhjaGrp0jE6MNe0adMqfy+77LJNKkn3omMU335G7VW9v/eJ6gM/filJGe7rk+jdnn8Pqu22vico/R5K91P6nWCu3KXv982YGQ4AAAAAAAAAAAAAAAAA0A3wYzgAAAAAAAAAAAAAAAAAQMurKbeKnwZQp9rTaemmT5+eYp+aRKfq0yn0/VTq0fSfuZSi0bR5pSkrctPulaTW06lMvShNUVv7KtHVUmbmUp1EU0nm0jjoOZk4cWKKN99888o60dTcOm3j888/X/lM06eNGTMmLLfeuxrXYwr5km10lVQNzeafj9/85jcp3mSTTVKcS4cR3VsrrrhiZbn77rsvxTq1+6qrrtreYqOOtA5YcsklU5xLXTF48OAUjxs3rjEFazFap/j2vJb0UlGaTZ+OXNOI6bOo6fd8ysUBAwakWFNhaN2Zq0d1+nafSmPLLbdM8SOPPNJm2fz50TZF03a2Et8fi/oReh58Xap/ax3ppybWv6dMmZLi5ZdfPsU+rZ5eT71m2v/y/SxNdb3WWmul+Lbbbqssp+kdoumbfZqG0imfo+mko5Sbfp160/L5ax6lnaqlH+qfK5/CZq4vfelLKd5uu+3avZ8crYN8n0mvX2naQL0uWm/5lF9aP+g29L73Y5T2TN/dXrlpzFVJOhazeNy0zTbbVP7W1BgXXXRRivU6b7XVVmF59J7RY9C+mJnZyiuv3Ob6/v4uSWuZGztq7NeP6j7lr3Fperpa1Dtlht7Teuy5MWstY6MoZaan+82lF9BroXVSaZ8ml76oZKzdFdKilsqdx9J7qDRNalSHlKbu1u2VppWqt+i+8c91relem0FTTueeP+2Dn3baaSk+7LDDOrT/V199tfK3nkuN/Xs3TcNdS3rW7qLk/ain97HWl/6+je7jXFuj9d/777+fYk3DmCurls0/V1pWrbtyz1stqZ9VV0mJmSuvprXU5XzK7qiu9X11PZ9RX9KnYH377bdTvPTSS6dYx3j+XD777LMp/va3v91m2cyq79xOOeWUFOv19H0w7XvpfVTL+/Kunuq6HpZYYokU6xh98cUXb0ZxitSaFjXXx0PH+RSJ+pzquGCxxRbrtDJ1Nbm+d2lqb6X1fun3RVG7+8QTT1SW23nnnVM8bNiwFI8dO7ZoP8q3Y/qeTevs0hRpen58fyE6Jzzz9RG94zPr2SmQG6lfv34p1menq6Uz9+k4/fdAaI6ZM2dW/ua61Ef03t8sHn/k+gD6LrW0vYrGiH5sFI2Xc2PM3HeoqiQlrP+ur7Tdj8bvuT5Se1LRMjMcAAAAAAAAAAAAAAAAAKDl8WM4AAAAAAAAAAAAAAAAAEDL48dwAAAAAAAAAAAAAAAAAICW95l5L/JpvXv3LlrurbfeSrHP5655cIcMGZLi0hyvueVyuW/n0nzbZtVctbn1J06cmOIBAwakWHMxL7HEEvPcf2k5m0lz9GpsVr1+mqdXr7PPdazHmzv2aNt6zVZbbbVs2efS67rssstWPrvrrrtS/LnPfS7Fzz//fGW5KMey8vd3lN/YnxOf43iuXB7knuS5555L8RtvvFH5bJdddmn39j766KM2/33ChAmVv/fff/8Ub7LJJik+88wz271P1M4/i+uss06K9VnS588/52+++WaDSte6NI+8zwGvOd31HGu7rznt/d+f+cz/61b4dkPrQv1svfXWS/HgwYPnWX6/vi+P1p+5HPcPPfRQir/61a+mWNsG39f43e9+l+LvfOc7KS7Nd69xSdvSCP6YtI3Rz/Sa+zZOl9Nr7i2++OIpfv/991M8bNiwFPtrFN1P/fr1C/ej5/Kzn/1sil999dXKcmussUa4jbn69u0bfpY7Vi23njs9V7lnojOV7Le0rHqNPT0PM2bMCLet95deSz2n/r6NxgG+z6T12Jw5c9rcj++baXn0fvBjh+h5ju7hRisdn0X8Ndbj1TruwgsvrCz3+uuvp/jWW29N8fnnn59i//zefffdKda+nl6/d955p6jc/vrpvaH9Pr1G2taZVY/P359KP8vV+1F56k2vmb/3o7pHY1+3R+chV2dE97hfR7cXtSGl9U7uWPWalz5//h7qDnJj8hK5axH1X2p5j6N9UrO4HqvHeFjPid4nub5ixN+bjXzO603rVn3m/TnecsstU3zYYYfVbf8rrbRS5e/bb789xbvuumuKp0+fXlnu4osvTrGO9w488MC6la2riNquHL0Htb9jVr3HO9pX8PWJ9pO0/6PPmx+r6WdaNt8maVlnz57dZhnq3ZeO2qq2/q43PX7f59TzvNNOO6VYnwv/nOqY9phjjkmx9s9yZfj73/+e4ssuu6yy3K9+9asUb7/99inWsXKfPn0q67z99tsp1u8K/HL6zmevvfZKce4dhsq1/VrP6bXWZ84/I139vX0tFllkkRS3UvtVi+7Yx+tKtG729LkaNGhQZxSnSyr9/jJ6x5m7h3Xb/lpoH0+3oetsscUWlXXOOeecFN9yyy1t7tO31aW0btb6POoT+LKW9o06OgbCp+Xel3GO2yd6/+5dc801Kf7e976X4l//+teV5Trar6+FHsP6669f+eyPf/xjildZZZVOKxOqtJ9tVv0OBrXT8Zkfv0TjhdxvPKL3Yn45bRtLf3NSS90cja98/0LHpdG7Zn9+9P2E7se/J9By63t73V5Hxi7db1QHAAAAAAAAAAAAAAAAAOhx+DEcAAAAAAAAAAAAAAAAAKDlFefu0WkA/bR/0fS0O+64Y4pPOumkymenn356ijWN1e9///vKcjrluk6Hl5uWt2QawFxqm9x0r1OmTEmxThGo0wAuueSS89x/e/fbDDrloJ+yMJp6Xv/dT+kYTReZS8Oi0yHqlJ6PPfZYUOp46ns/haKm6HjiiSfC7akolZffdmnqhpJ0qP756mr3ST1o/fLzn/88xT/+8Y9T7O8Tvdf0/tTz5VPvRKl6Z82aVVlu9OjRKR4zZkyKBw4cmOIRI0a0cSToqPvuuy/F22yzTbicPgcbbrhhiv/85z83pmDdiE5H658RP41tW6ZNm1b5W58LvS79+/evLPfee++lWJ9fTT+eS5OqZdWpwHNpEXO0rLfddluK11xzzRT7NJtHHnlkijfddNMUa6ptT8vTrDo7SndoFk87rHIpvnNtnKaTnzp1atE6HT1HOp38j370o8pnmjb5m9/8ZopL09vrPePbfT2mqJ32qbr1Oaj3vaF91Fzq14hvc/V4NfbpzpQ+s1pv+Osf3Q+59Il6jktTRepner79tqPPfAqCaGpunf7bX9eov1IPek78eYj657k0vqVpQHXco+2Lpkj42te+Vlln8uTJKdYUysqnsI/kpkiP+ta+rtNzl0uvFT3Pei39GLWz6v3cedA2QO/jWlKJmcXjIVWaKl3LXZqKzG87uhZ6DP5e0L91/dL7vquL7rvSMX3uWkSpGUqfxSgle24/uXFgqVr6Y1H/qZXTyum51OPz50TT6DWSpnzU1IsHH3xwZTltN84666wUDxkyJMX67rC7KG1TtB7zy0Tpv3NjqFz9qXS8F70f9fVq1Ifz9YH2p+r9/EX1WK7uK01tVSs9/6V9RE0n7K+TXo//+Z//SfF6661XWW7vvfdOsbYR999/f4p9Wi519913p/iHP/xhitdee+3KcieffHKb62+11VaVvzWlq4rad7P4evh3HVE7EKVMNaver7WMqboi7a+/++67Ke5oSrPSdPfoPsaPH1/5W8dY+izV+j1Zd5BrQ6O6Kzceidoi3/aXPH//+Mc/Kn//6U9/SvFSSy3V5jq5lJlaB/jj1jZet6F9Uf9eQOtc7fv7elrbO+2/ahn8GKje72K6M98/03fIrTwmaobS8/WVr3wlxfr94zvvvFNZrhnpL7Vs+vyaxWMOdC7/PXcz0ul2R6XnsfS3G/X8vjBXttLy6LhJn+Xc+CcaR/u6QMceuffvjf7dCyMTAAAAAAAAAAAAAAAAAEDL48dwAAAAAAAAAAAAAAAAAICWV5xfQqe581PJ6lSzOn3dwgsvnOLclMgvvPBCih9++OHKZ1//+tfnWZ5aUnLk6DHccccdlc80baMet6bp23///Yv2k9tvV6BpCXJyKZZUdC186ge9tjrF9owZM1Lcr1+/cJ0oDZaXSxuntHw6pWMuTVw0TXRpylSVS6vWXWjqulGjRqVYj9WnONBrpqkLtc7YcsstK+voM/vVr341xXvssUdluT333DPFmsLxnHPOSbGmhjT7dCoXlNN6VlMXevo877rrrin+3e9+15BydVe5tH8qSrm32GKLVZaL0qgvvvjileU05ahuT9OP55ROtx2ldvP1r95PWjfotPq+/lWtNB281pe+zS1JjetFUxr7bWs9qVPpK3+O9TrpdSlt+3T6Zp/SR+uNoUOHtvnvnt7fudTrSp+rXJqoXMqMjipN4xM9L6VTVfv6QOm1HDduXLhclAI5d/213Fq2XJ2m93ppGtkoPWyO9hVzdUgj5c6XlkmvUe4Z03Ps+2OaAlVTyz/22GMpvuyyyyrrzJw5s839HHTQQSk+/PDDK59Fz0stz6JvD6L2JbdclFollxq3WX34Wur53LFG16Lk/JjlUxurKJVeaapl5fej62jdXJriK5eSsCSNbLPU4x4sSQvu1dJnKk1dqEpTq+beEUXtdq4f2kqp4F577bU2/9334XJp0BtF3x/m6l9Ny3bfffeluLukSY3SlZrFz1yurtFzp2lz/Du1aNu58ugzou9NSu+fadOmpVj7Zv5v3a/24X0fLkoLru8SzarpXSM+9VOj02hHKb/NquMobdPfeuutom1PnTo1xWeccUbls0UXXTTF+gwts8wyKV5uueUq67zxxhtt7uc3v/lNin2fPKpDv/CFL1T+3mijjVIcjRE8PXda15emM9J1fJtQ+l68o0pTv9bD0ksvneJJkybVbbut1BaiPvy7vOidT09Ok5p7LrSO02c+t07U163lXdNdd91V+fuJJ55I8bHHHjvP9c1qS/OmdbbGgwYNKlrf32f6DlfpOe2O36V1Fn++o7EgGuOSSy5J8VlnnVX5TNPTr7766g0rw2abbZbiX/3qVylee+21G7ZP1M6/f29GOt3uKNfGRe12ro4s/X1TNEbXd825d6Q6/texkR9vln4/oKL37L480ZjOj7P0+xTSpAIAAAAAAAAAAAAAAAAA0AZ+DAcAAAAAAAAAAAAAAAAAaHk1pUn91EYKps3zU2/rdHg6TZ5PqxYpnTK8o1OL//nPf678rWnedCrBrbfeOsVbbbVVuL3SVCKlyzVSlKrKi1JsedF9kkvpoKkJfBqHaLnSFChR2jg/fWV0/nP3Vi3XLEqL4LfVSqn5Sq2yyiopvvbaa1Os6U8nTJhQWee73/1uio866qgUP/DAAynO3bdLLbVUin2a1LFjx6b4hBNOSPH666+fYp/OAe2j6XD9+Z/Lp7XQVIY33XRTQ8rVE5RO06/1kNY7uZTFqjQtSe45VVHqwVwbovWnL7eWT9sNnWI/l/rsvffea/Pf21qvLf64Gzltfy5Nn5Zdl9Pr6lM9RuvkRClmSlPp5VLSlabQ0Tpcj6+0r5CbgjqXOr0r0+ONpts2i+/PZZddtmg/vg2Pth2lsPepszQtlpa7NA2W3nc+hUhpevuS+87fq428N7Q8Pi2mPn+1pMxU/pndZpttUqxpsx555JEU//Wvf62so/W50vPlz5XeG7q+v1d1G6XpZnQbufMT1Um56eAbWbfn6q5aRG2rb+OifUVprj39TK9XaUo6Xx49D9E5yaUn0Ge+NH21nh+fOkb3W+80qaXXvLRdLN1e9G4i91xF7whquealbVIu3Xdp3R591kpte44/53P54ytNt15Pe+21V4qfffbZymcXX3xxivX+1vd1Tz31VGWdVh2v67XIPSOl7wx1e7n0oHpedXu5Z0eX0xSbWm5ft+i9FY3HzKr158CBA1M8cuTIFG+44YaVdaI6xN/P0bgiSqHdGXLtRdQ3Ofvss1OsY1Mzs9tuuy3Fej3++c9/VpY7//zzU/z3v/89xZq2ePnll6+sE6VJzbW7Ud/bXxvdht4fuk6uX6KxHz8o7UvqOr696ax05/V+z9vINObAXJoe2yxO+VWa/rI7ilKhmsV99NJ+fK5+0m1E7dkxxxwT/u3fn5bI1TvROLOWOlbbJ79tlUuBjdrptR0wYEATS9IzbLLJJin25/sXv/hFig899NAUr7POOh3a5w477FD5+9JLL00xqVG7vpkzZ1b+7ug7YPxXad9av5fIjb2jbXs6NtG2ORrLeL7NnMu/+4zesfnlSt+zq6gv478bKDnHvn/SnvSu3eONHgAAAAAAAAAAAAAAAACgR+PHcAAAAAAAAAAAAAAAAACAlseP4QAAAAAAAAAAAAAAAAAALS+fRFXk8uAqzSGr+WOnTJlSWS7KY+tzX/uctPNa36yaR3deeWLb8p///CfFkyZNKtrv4MGDi7ZXeh51OT0efz4WWGCBou3VQsvgy63HpHl5dTl/rrTsc+bMSbHPW625gRdccMEU566r7lf3o+X0csdXT7Xcjx999FH4WZQburtYY401Unz//fe3e/233347xf369at89uGHH6Y49+wcf/zxKf7KV76S4iWWWCLFyy23XLvL1pNdeumllb+/973vpVjzhi+yyCIp3nfffSvrnH/++Q0qHebK1eFz+TzvUXvg6/aoPY/+3X+m5dHn19eXegxaNp9TXrc9YcKEFE+fPj3F2h6Zma255pop7t+/f5v79KJ897490Hax3nW77kvbJP+ZP965fH0Z1Z9+2yeccEKKl1xyyaKyaj2t95rGeo3MPt13jJx88slt/rveQ/7YSq+Llluvc279XF+2o6Jnxyx+ZvUYtP+VM2jQoKIyTJw4MVxOyxftt2/fvkXl0efS0+PO9QH0nOSukd6Teqz6HNUyDqmVltuL7t1cH7V0/KLb2HLLLVO81157pfiGG26orKPPxTbbbJPis846K8X+ePQYcmMjvWZ6DLpPfz9Fx5erL/UeamT9nVPvOkSPSc9rLeOk3Bgsei5y97Cq5b1EqdJzqtv2/Z1Gyj2Xer/6vlqk9Hijc17L+tof83V+Ledfz0numuv9NXv27BSXti/dxcsvv9zmv/tnNvd+qzOce+65lb/HjRuX4htvvDHFTz75ZIp/+tOfVta58sorU7zMMsvUu4idwj8j2seIxhil/Ngoev5yz9Wtt96aYi2r1ou5+kiPwbe5+sxq+5RrXyL+2KJ+4IwZM1Ls+5QdPd/zUton0/Oi9ddFF11UWeeNN95I8Z///OcU+7Hz6NGjU/zQQw+lWI9fz0tO1B/2f59zzjkp3nPPPcPtRe/v/PmJxrC+fdZj1/Od23Yt91tXkLtHl1pqqRSfdNJJKb766qtTPH78+Mo677//for1Or/33nspnjVrVmUdvS7XXnttinPXHK3FtyP6LOn113uup9F6LPeuQum58+dY21RdzrdzJWMBX79p+1K6n2hc7uug6B1uPb7XjLbhz50qHSv1VFG7albbmBP1sdZaa1X+PuKII1J85plnpvif//xninXca1Ztz7Xd1vpg2rRplXVGjBhRW4HRFP73LOuuu26TStK95PrW2t5Ebb2vV6PvYH3bHH1PUjo2LX3PGums767MysbYvt1pz3tfZoYDAAAAAAAAAAAAAAAAALQ8fgwHAAAAAAAAAAAAAAAAAGh5dc/dE02bp2kNzKrTBCufjqGWafii1Cs6XaHfrv6t6/sp5HXaPZ2iUNMnerUcg5a1WVPO6pSM/hii6RVzablUaTqZKB2AV5Lazystq07/q2UonWIydz/pZ7q9XAqcRqbG7Q50Kl8/JbZey2HDhhVtb4MNNqhLuXqiCy64IMXHHHNMuJxep4022ijFpEVtPD+VrNZRWvfkpt6N6kJNeZuj1z83ZbCK0pp4uTRYmmpz//33T/FTTz0V7l/vSa0b/HmsJb1cI9N159I2an9MP8u1v9GU+X7bmvZ64YUXLiprSdvq06Lq+S5Nn1jalkYpD/05iKat7uh01LUq7QtF6Ydy97TGiy22WLhtXW7q1Kkp9udOr5mWux79X61fSlOWRucul0YkGkd0plwdouXT6+L7pZHcfazbXnHFFVN81FFHpVhT2vkyTJkyJcWLLrpoimfOnFlZR8cOufTOUZqx3NgjOj5/LaPxWXR+/WetpJZy5+pffX6i+rLWdrB0TKc6mp4n167WUp5Spc+5iup5s+q9n0vRV4voudBnp/Tc++c32nYupY8qTY0apcfz93dpeu2uwNetc/lr3uw0qd6FF16YYk398sgjj6T43nvvrazzs5/9LMVnnHFGihdffPFGFLFTRO1V6Xsz5ftZuo2ovfPPmN4nUZ+itP/k14/GDrnji86DX0f3pfe+prXp7PSYUV/brFpebUP1evhn9re//W2KX3311RRPmDChstzBBx+cYk2H6lNeKj1nSy65ZIrfeeedFOfur6uuuirFO+ywQ2U53Z4eq54Dfz2j1EJ+Of07Gvf6697IMXqzHHrooSnedtttU6xjbN9X08/02dS+e72/u6ilXkPn8t/16XOq12/QoEGdVqauRtuVDz74oPKZvmvSekz7vbn0X1o/6ftNs0+/M2uLf66iMUyuHqzluS/t/0fvLUpTn2vZ2pNGDfnvhPVclo6pkJe7P3NjyzXXXDPF+h3c5MmTU+z709puax3UrPeYqD9NhWtGOuPOEJ3j3Hee2tZre+zrA32fp/1zbZvnzJlTWUff7Wk9XUt/WrdlVq0rSt99lrxLr5VuO3rXPBejCQAAAAAAAAAAAAAAAABAy+PHcAAAAAAAAAAAAAAAAACAltdp81/66fSUTun3+9//vvLZ8OHDUzxkyJAU51KTRGqZElJTMHiaYiKXRiI3tazqauk1apk2UafV9yny9Dzk0plE0xuXlidK+eandY6mcfTpGbQ80X2cSyGnn/kyROlQS1MA4tP0nObSf0Wp79A+/hyffvrpKdbUNH5aZk27oc/fww8/nGJft5emPlI6Fay2AQMHDqwsp/eDps7RMuy1116VdTSlSKvydVo0jXxpm6TT8pamFNF7IbdOafouXU6Px08Tvd9++6X40UcfTbHWuT5NSpRSJ5f+R5WmHq13vR+1SWbVc1RLavLcdO763JempIv6Cjm1pD9VuXX0ftLj9nVf1IZ3henIc2kb9Xzn7sEoJZ32zT1dR1OC+Oc8eu6jqcC93L0Vnf9c6udILo2IHl+zUkWUjoe03FG6qPbQ86djo2WWWSbFZ511VmWdX/ziFym+5JJLUqzXsl+/fpV1ovvW3996HJoqO3espSmio/pS78+umIIlaj/1/JjF965v4/RatGdK+ra2p/2GWp+dkj6K1idm5WWNxhJRKnn/d73bgFzfLBpXlqYhyNUB0X5z5dF7I1ou17eP2hBPj7uWPkDumS19/xClfeiKjjvuuBQ/++yzKf7c5z5XWW6zzTbrtDKVWGqppVI8dOjQFPtnW11++eUp3meffVLc1Y6tPfS5iNIcl6Y9y9H7OJeeskRuHf0sSoua49P+lo49SuqKzk7LqPW2v05R/ZxLrap9dE096usoPYdvvfVWivVduE+FOH78+BTffvvtKdaUmy+88EJlHa2rX3zxxRQfccQRleVuvvnmFC+xxBIp1ms2bdq0yjr+3XMkek60bD0hTdiqq66a4hVXXDHFXe3Ya3kGc+Peeq6D/3r77bcrf0ftTekz2t1pSjSzampTreN0OX8/Ru8x/Ni5Ftpu1tKfzY2jo75E7l2MHntpeaL9+PLo2MJfF1T7ALl31zzb9VGPdkf7ehqj59F3sWZmK6+8cpNK0r2UfqcXfWfm27HS1ORRO6nvoEp/55D7nVL0bjc3PojqrtLf+9SDf1+dw8xwAAAAAAAAAAAAAAAAAICWx4/hAAAAAAAAAAAAAAAAAAAtjx/DAQAAAAAAAAAAAAAAAABaXpzwtc5OP/30yt+vvPJKil988cUU33LLLZXlBg0alOKzzjorxQsvvHCKc3lrI//+978rf2uO3u985zspfuqpp4q2N3DgwBTPnj278lnfvn2LtjFnzpwUl+b57Sz+fOk5/+ijj1KsueL13/06eqx9+vSpLJfLvxzR/MSa0zhHcxfPmjUrxf566bHrMeg9M2PGjMo6/fv3T3Etx6PHkDv3+LSjjjoqxVOnTq18ttxyy6X4wAMP7LQydWdal5uZ3XPPPSnWZ8TXi/pZtJz+eymfg1y3p/XO+++/3+5tv/baa5W/NWf7QQcd1O7tdQWlOdu1jtUc8p62XVFOe++www5L8QknnFD5TK+ff57n+uCDD8Jta33p61Klx6fLrb766pXlova8tG7PlaGR7b6eBz1WX6aobc/dJ7lj0vav9FpEbbi22aX3Vo7eN74fonRfH374YYpz1yvq73Rm307LmusX6bHr9crRe2jw4MHhZ1qHjx07NsV6Tsyqz4+eO73vfNl027qcbzei8tRyP/lt6zOi5zh3zaPnrR70mDw9xuh8+7o0ei78tdDt6fhM4xEjRlTWWWGFFVK8/vrrpzhX7+i50+vqz6Oeh9IxWMl+fJn0PER1XVcR3eOlYx5Pj1fvfX1GStsaLUPu+e0oXw9G19mfq6h+0XX8s9fIeyB3TqK+SG6d3DUr2Yb2Cf0yvXv3nuc+/TLaduXKpsda2geL5I5bjy86HrP69Es6yyqrrJLiX/7ylyn+4he/WFmuns9fvR155JEpfvzxx1Psx6Xf+MY3Urzeeus1vFydQdvJ6N2Up/exLuf7KNGzFI0PzMxmzpyZYn0XWMs4vpTWudrX8ErHuRH//kLPV0frnbbkthl9luu763XTc+avjb7/jq5brj7QMvzlL39Jcb9+/cLldHujR4+uLBfVp9pul77z9aKxmJ7fRvZFuqKu2G/tiFquV3e/xo3kvwvRfn3uexb8l7ZhUT3k78+ojsz1RbUfoMv5dXJ93RJ6DL6/ELXJ9X7PF7338Dp6rN2dtrP+XOXewQNovtNOO63ZReiWcv1FHadoOxSNx/xyKvf9R64Nj5S2s1rXaz3v228tX7RO7nu20vfOpePS3L48ZoYDAAAAAAAAAAAAAAAAALQ8fgwHAAAAAAAAAAAAAAAAAGh5vT6pYf76XHqcUjfffHOKDznkkBRPnz69spxO4/ezn/0sxccff3y4f/27NE3U5ptvnuJHH300XE6n4dPUrz/4wQ9S7Kd/riVNZqSrpMyMpj2MUgaZlZe1lpRiUXly00BGn/l7cMCAASkuvZb1nOa5Hs8b0FnGjBmT4hNPPDHF/r6dNm1aijW9ik6zP3ny5Mo6OoW8pszUbfmpUv3U7BGta3QdfZb33HPPyjqXXHJJihdddNGi/XQF9WyTcg4++ODK35dffnmb+43SrZlV2/Aozaa/5qXdGk3DvuSSS6ZY7zOftnWXXXZpszx+n3pM2gbkUgCW9le6slyqHr3muTZSUzhE94ZP1avTMms6Dp86qST1q7+WWtbS6Zt1P7n0C6Xp15ohdx6iFKVmZWlm9BqZVfvNUf2US62q9YGv02pJTVvahyt5Zv29GqUorQcttz8PJdfFt5fRdO6l5Y7SobdVvrb245eJ0hT7eidKWRo9o2bx8+evn24vOgZ/r+q9Ue80TLW059rnyqWXU7np/KMy+HX02EvTvUXPee65jM5xadqz0tQFpSl9O3Os3tE2RVMClqazKk2zGvHPYvRs+7q8nul5tG4xa90+WE/14IMPpvjZZ5+tfKbvGUvru64gV7d39JkrTake9YW0DfHl03pD18+lOS6l9VuuLa6lPx69L+homtV6ilLc6b1SWt5cWxulvvbnqKSNmDJlSuXvxRZbLMX6PN54442V5XbaaacUl97vpe2fvmvq379/u9dHYzSr34SO22yzzSp/P/bYY20u984771T+HjJkSMPK1B1oPe37qfqdVy19gnqnJY227em+9Ji07fJtuvb3tX9e2o/InZ+O9qe6u3fffTfFSy21VLjclltumWLtkwNAT1LLWML/zmcu35Zq+1dLn7n0+8bSdjFaLvedYPSevh7a057zqxoAAAAAAAAAAAAAAAAAQMvjx3AAAAAAAAAAAAAAAAAAgJZXU5pUr6NTy95www0pPuKIIyqfaSo8nWLwsssuS/GwYcMq6/Tr1y/FK6ywQop1WvbVV1+9ss4rr7zSZtn89H5XXnllig888MBwOdXRNHS5NAmNnN641jLVU5ReIZc6KUrvUI+UJ1EK19LUO17Js1PrtgGU82k85tLpZwcPHtxZxenSfHundZR+5tvVk08+OcWaKl359C6laW6VtgGa/sRPw3vmmWem+IADDgiXi0RpI3Pb0OX8dMi5dLGNFLXnpalo9Vhz90Y9+yi5NKmlqRCjqaX9MURpG3PHo32F3PTYjew/aRl8WaP0SqVpYHNpkzSFgtarek8///zzlXVWWmmlcL9z+XMV1Q256cSj/lOunsmlnIrSgOSmCdfjqPf1z/Up9X7QYypJXZnbj99G6XTptdQNpWOeqE7LnR9dR/eTa5OiMUbu/HRmHz5Kh1qaplrrrlydW4uo/vXtopav9LmqJW2Abs9fo5L725dbP6v3+LyW4yvtr9TyXiGXDqIkNXmtoj6KlpsxNFpVLs2YitKX+pSw0bvKXIpRXUeft1rGKLWmIi5N6aK03snVYyX9A00dbVaePrpWpdcwSmvq22p9XxnV9X57pallo/eiuffi+m5A119zzTUry0XjzBy9brm2LPqsWe/VgVbnv4974403Uqx9P98O9KQ+mR67r9Oi+jw3ttS/c+P3qB9e+n1etJy/lrqcpnDNtaFRW527L7Td0P2Y5dtP1EafZf++Tu9jTZV8//33N75gANBCou+UzGrrC+m4vLT9rOUdYqloTOjHm9F3AL7c0XsQPXcd6UMyMxwAAAAAAAAAAAAAAAAAoOXxYzgAAAAAAAAAAAAAAAAAQMsrTpNamgq1oylT/fT3Oo1fbsp1pdPm6To6VZ+fQl73+8EHH6T4oYceqiy3xRZbtLmfUrVMS6hTEPup6jtraulc+pdoGvvp06dX1hkwYECb6/jrGqU3qfexll6LkrQS/vyUpMgzKzumzko7B6BnKG1Tou6BToFr9ukp6iNvvfVWiseNG5dirUsHDRpUWUen0h84cGCKo3SXfp3S9DozZsxIsaZW9aJzV9o+5VKVaV3f0RR07aF9ntJrqWWtpU3KpWCN0jbm1tHzWsu5i1Ky+zKUpmCNdGYqvVzqulqWi/pM/j4+7rjjUnz55Zen+Bvf+EaKNWWymdmSSy6Z4iiVnp8qu5bzpddMj8FfS/2sWSkua6HXyI9RojFLaVqojqYozaW1LK1XozTTvs+tZY364/5+0r/1mfBpVkrOQ+mYoB5KxzIdTVeZu36R0me2tGy1pMvTa5nrKyif0kffH5SO/UvTD7USff5K0zOVbKve9WruGW3kdWnkMaFnqyU1eT1EKV1yfaZG1nf1PtZoe41M79we/jwrLVcupW5pP6UkxY4vj56/eo9bo3o89w5D6/fSfqrup5nXOtId+xIlaE9bm/abX3rppRQvv/zyzShOl+Pr0qg+13rMj030nZ3W574e0+2Vvi+Lnr9cfaTl62g6cf9dbWkfI3pPp8fqt92Z71xb3Ztvvln5+wc/+EGKf//733dyaQCgOXJtYfQbptK2JpdSXdtj3U/uu9HSFKqRWsYhuk7u9z4d7d/X8vuauXrOiAoAAAAAAAAAAAAAAAAA0G3xYzgAAAAAAAAAAAAAAAAAQMvjx3AAAAAAAAAAAAAAAAAAgJbX6xOfZDWQy/mquecXXHDBDhXonHPOqfz9/vvvp/jtt99u89+nTZtWWUfz1es6kydPTrHPJat5efv165fi6dOnV5aLcuRqXl7NgWtWzWNbmmNXab57X27dXi3bLuXzDmvu4iiHsL9P9Dg0XnjhhYvKoPeZP1Y9L3q+P/jggxT7e9Nfp5L9RjmI/WMUXbOOPh++PKXHAAAl5syZk2Kt53Pti36m7W/fvn0ry2ndpbQey+V917IttNBCYXl82zOX1stm1fpY24o+ffqE267Fv/71rxT37t07xR3Jcd9ejWw3dNt6/c2q90C0X39f1FK+qI+q93ApvV5m1f5h//79O1S2RvbT2iMq08yZM1Oc65tpn9CfYz1f119/fYo322yzFK+66qrhtvX8azn9M6/Ps94z/hzrc6bPmK7vn0V9TpW/V7V8ug09J37b0XKNptesdNym52iBBRbo0P59vVzyLPg6W8+X3ie5Y9B2Q6+r37/e+3qv1XKN6lGn1YPWx3rs0RjOrHpe9F71xxSdl9w9E7VDufZJy6D3cC33Yy33YFfnj0nruEb2KaIylJ5T7XP5uj16NeW3XdKv8fdtdH8ynkZXlnvO9Z6O+i618m3wXKX1b9T/Misfl+Te/0XbjpS2Abqc33ZH3+vOSzRm9OUq3bf2A3R8W4/2Qa9N1Lf191B079TSPmu/zaz6Dl/L5vsrUbn1PvTnJ3ddWlUz3inn6oRG7afR+8Kn5d4H9lS5dywlz4W+XzGrjn31s1q+b/LPi/bR9frpfnLPVC11pNZHvu+uf+fe02p7o22I1t9+/a74ng49V3d8VwF0Z7mfVGk7GY09zKrvOPW9mG/3dRvaNjeyHSsZh/vlcuOpUtExlZ7veaFmBQAAAAAAAAAAAAAAAAC0PH4MBwAAAAAAAAAAAAAAAABoecVpUgEAAAAAAAAAAAAAAAAA6KqYGQ4AAAAAAAAAAAAAAAAA0PL4MRwAAAAAAAAAAAAAAAAAoOXxYzgAAAAAAAAAAAAAAAAAQMvjx3AAAAAAAAAAAAAAAAAAgJbHj+EAAAAAAAAAAAAAAAAAAC2PH8MBAAAAAAAAAAAAAAAAAFoeP4YDAAAAAAAAAAAAAAAAALQ8fgwHAAAAAAAAAAAAAAAAAGh5/BgOAAAAAAAAAAAAAAAAANDy/j+VKiqv11tzjQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 3200x200 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Generate 100 samples PER character (not 2000 total)\n",
    "all_X = []\n",
    "all_y = []\n",
    "font_sizes = [11, 12, 13, 14, 16, 18, 20, 22, 24]\n",
    "generator = RobustTextImageGenerator(IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "for size in font_sizes:\n",
    "    for char in MENU_CHARACTERS:\n",
    "        for i in range(100):  # 100 samples of EACH character\n",
    "            img = generator.create_text_image(char, size, None, True)\n",
    "            \n",
    "            # if img.max() <= 1.0:\n",
    "            #     # If values are 0-1, scale to 0-255\n",
    "            #     img = (img * 255).astype(np.uint8)\n",
    "\n",
    "            # pil_img = Image.fromarray(img)\n",
    "            # pil_img.show()\n",
    "            all_X.append(img.flatten())\n",
    "            all_y.append(char)\n",
    "\n",
    "    \n",
    "X = np.array(all_X)\n",
    "y = np.array(all_y)\n",
    "\n",
    "# fig, axes = plt.subplots(3, 4, figsize=(8, 6))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for i in range(min(12, len(X))):\n",
    "#     # Reshape flattened image back to 2D\n",
    "#     img = X[i].reshape((IMG_WIDTH, IMG_WIDTH))\n",
    "    \n",
    "#     # Get label\n",
    "#     char = y[i] if isinstance(y[i], str) else y[i][0]  # Handle different y formats\n",
    "    \n",
    "#     # Plot\n",
    "#     axes[i].imshow(img, cmap='gray')\n",
    "#     axes[i].set_title(f\"'{char}'\")\n",
    "#     axes[i].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(1, 10, figsize=(5, 5))\n",
    "# for i in range(10):\n",
    "\n",
    "#    j = np.random.randint(0, len(y))\n",
    "#    img = X[j].reshape(IMG_HEIGHT, IMG_WIDTH)\n",
    "    \n",
    "#    # Get image and label\n",
    "    \n",
    "#    char = y[j][0]\n",
    "#   #  pil_image = Image.fromarray(img)\n",
    "#   #  pil_image.show(char)  # Show image with font size as title\n",
    "\n",
    "#    plt.figure(figsize=(6, 8))\n",
    "#    plt.imshow(img, cmap='gray')\n",
    "#    plt.title(f\"Raw Image of '{char}' - Shape: {img.shape}\")\n",
    "#    plt.colorbar()  # Shows the value scale\n",
    "#    plt.show()\n",
    "    \n",
    "# plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "# plt.tight_layout(pad=2.0)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "print(f\"X shape: {X.shape}\")\n",
    "\n",
    "X_flattened = X.reshape(X.shape[0], -1) / 255.0  # FLatten & Normalize to 0-1 range\n",
    "\n",
    "# X_flattened = np.array([r[0].flatten().reshape(1, -1) for r in X])\n",
    "print(f\"X flattened shape: {X_flattened.shape}\")\n",
    "\n",
    "y_encoded = np.array([char_to_idx[c] for c in y])\n",
    "\n",
    "# one-hot now\n",
    "y_categorical = to_categorical(y_encoded, num_classes=len(MENU_CHARACTERS))\n",
    "\n",
    "print(f\"✅ Batch generated, X: {X_flattened.shape}, y: {y_categorical.shape}\")\n",
    "print(f\"   Y1: {y[0]}, {y_encoded[0]}, {y_categorical[0]}\")\n",
    "print(f\"   Y2: {y[1]}, {y_encoded[1]}, {y_categorical[1]}\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_flattened, y_categorical,\n",
    "    test_size=0.2,      # 20% for validation\n",
    "    random_state=1,    # Reproducible results\n",
    "    # stratify=y_encoded  # Equal representation of each character\n",
    ")\n",
    "\n",
    "print(\"🔍 DATA VERIFICATION:\")\n",
    "print(f\"Total samples: {len(X_train)}\")\n",
    "print(f\"Expected: {len(MENU_CHARACTERS)} × 100 = {len(MENU_CHARACTERS) * 100}\")\n",
    "\n",
    "# Check label distribution\n",
    "y_labels = np.argmax(y_train, axis=1)\n",
    "unique, counts = np.unique(y_labels, return_counts=True)\n",
    "print(f\"Unique classes: {len(unique)}\")\n",
    "print(f\"Samples per class: min={min(counts)}, max={max(counts)}, avg={np.mean(counts):.1f}\")\n",
    "\n",
    "# Are all classes represented?\n",
    "if len(unique) != len(MENU_CHARACTERS):\n",
    "    print(f\"⚠️  Missing classes! Expected {len(MENU_CHARACTERS)}, got {len(unique)}\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 20, figsize=(32, 2))\n",
    "\n",
    "for i in range(20):\n",
    "   # Get image and label\n",
    "   img = X_train[i].reshape(IMG_HEIGHT, IMG_WIDTH)\n",
    "   label_idx = np.argmax(y_train[i])\n",
    "   char = idx_to_char[label_idx]\n",
    "    \n",
    "   # Show image with character as title\n",
    "   axes[i].imshow(img, cmap='gray')\n",
    "   axes[i].set_title(f\"'{char}'\")\n",
    "   axes[i].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# label_counts = np.bincount(np.argmax(y_train, axis=1))\n",
    "# print(\"Label distribution:\")\n",
    "# for i, count in enumerate(label_counts):\n",
    "#     if count > 0:\n",
    "#         print(f\"  '{idx_to_char[i]}': {count} samples\")\n",
    "\n",
    "# # Are labels balanced?\n",
    "# if max(label_counts) > min(label_counts[label_counts > 0]) * 10:\n",
    "#     print(\"⚠️  Very imbalanced labels!\")\n",
    "\n",
    "\n",
    "# Visualize samples\n",
    "# print(\"\\n📊 Visualizing samples...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c87d209d-2760-47e4-b40f-48018a752b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (50400, 70)\n",
      "y_train dtype: float64\n",
      "First 10 y values: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Unique y values: [0. 1.]\n",
      "len(MENU_CHARACTERS): 70\n",
      "MAX 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_train dtype:\", y_train.dtype)\n",
    "print(\"First 10 y values:\", y_train[:10])\n",
    "print(\"Unique y values:\", np.unique(y_train))\n",
    "print(\"len(MENU_CHARACTERS):\", len(MENU_CHARACTERS))\n",
    "print(\"MAX\", X_train.max())\n",
    "\n",
    "# # 1. Class distribution\n",
    "# labels = np.argmax(y_train, axis=1)\n",
    "# unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "\n",
    "# plt.subplot(2, 3, 1)\n",
    "# plt.bar(unique, counts)\n",
    "# plt.title('Class Distribution')\n",
    "# plt.xlabel('Class')\n",
    "# plt.ylabel('Count')\n",
    "\n",
    "# # 2. Pixel value distribution\n",
    "# plt.subplot(2, 3, 2)\n",
    "# plt.hist(X_train.flatten(), bins=50)\n",
    "# plt.title('All Pixel Values')\n",
    "# plt.xlabel('Pixel Value')\n",
    "\n",
    "# # 3. Sample means\n",
    "# sample_means = np.mean(X_train, axis=1)\n",
    "# plt.subplot(2, 3, 3)\n",
    "# plt.hist(sample_means, bins=50)\n",
    "# plt.title('Mean per Image')\n",
    "# plt.xlabel('Mean Pixel Value')\n",
    "\n",
    "# # 4. Sample variance\n",
    "# sample_vars = np.var(X_train, axis=1)\n",
    "# plt.subplot(2, 3, 4)\n",
    "# plt.hist(sample_vars, bins=50)\n",
    "# plt.title('Variance per Image')\n",
    "# plt.xlabel('Variance')\n",
    "\n",
    "# # 5. Feature variance\n",
    "# feature_vars = np.var(X_train, axis=0)\n",
    "# plt.subplot(2, 3, 5)\n",
    "# plt.hist(feature_vars, bins=50)\n",
    "# plt.title('Feature Variance')\n",
    "# plt.xlabel('Variance')\n",
    "\n",
    "# # 6. First few sample images\n",
    "# plt.subplot(2, 3, 6)\n",
    "# img_size = int(np.sqrt(X_train.shape[1]))\n",
    "# img = X_train[0].reshape(img_size, img_size)\n",
    "# plt.imshow(img, cmap='gray')\n",
    "# plt.title(f'Sample Image\\nClass: {labels[0]}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Print stats\n",
    "# print(f\"X shape: {X_train.shape}\")\n",
    "# print(f\"Pixel range: {X_train.min():.3f} to {X_train.max():.3f}\")\n",
    "# print(f\"Mean: {X_train.mean():.3f}\")\n",
    "# print(f\"Classes: {len(unique)}\")\n",
    "# print(f\"Samples per class: {counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f0073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generator.visualize_samples(X[20:40], y)\n",
    "# X_train = X_train[:100]  # 10 per class\n",
    "# y_train = y_train[:100]\n",
    "\n",
    "# simple_model = keras.Sequential([\n",
    "#     Input(shape=(1024,)),\n",
    "#     Dense(512, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(70, activation='softmax')\n",
    "# ])\n",
    "\n",
    "\n",
    "# simple_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # 2. Train on small batch to test overfitting\n",
    "# # X_small = X_train[:200]  # 20 samples per class\n",
    "# # y_small = y_train[:200]\n",
    "\n",
    "# history = simple_model.fit(X_train, y_train, epochs=200, verbose=1)\n",
    "# print(f\"Final accuracy: {history.history['accuracy'][-1]:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47d3fb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 13:03:18.051837: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,550</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m147,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)             │         \u001b[38;5;34m4,550\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,886</span> (667.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m170,886\u001b[0m (667.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,886</span> (667.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m170,886\u001b[0m (667.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1260/1260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3514 - loss: 2.5545 - val_accuracy: 0.8773 - val_loss: 0.3554\n",
      "Epoch 2/5\n",
      "\u001b[1m1260/1260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8965 - loss: 0.2894 - val_accuracy: 0.9251 - val_loss: 0.1885\n",
      "Epoch 3/5\n",
      "\u001b[1m1260/1260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.1713 - val_accuracy: 0.9137 - val_loss: 0.2148\n",
      "Epoch 4/5\n",
      "\u001b[1m1260/1260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.1382 - val_accuracy: 0.9469 - val_loss: 0.1204\n",
      "Epoch 5/5\n",
      "\u001b[1m1260/1260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9526 - loss: 0.1135 - val_accuracy: 0.9429 - val_loss: 0.1464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7eb8eeffb470>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# cnn_model = ocr_cnn(IMG_WIDTH, IMG_HEIGHT, len(MENU_CHARACTERS))\n",
    "\n",
    "cnn_model = keras.Sequential([\n",
    "    # Input(shape=(X_train.shape[1],)),\n",
    "    Input(shape=(IMG_WIDTH, IMG_HEIGHT,1)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(MENU_CHARACTERS), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "X_train = X_train.reshape(-1, IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "# cnn_model.summary()\n",
    "cnn_model.fit(X_train, y_train, epochs=5, validation_split=0.2)\n",
    "    \n",
    "    # for char in ['A', 'B', '1', '2', '0', 'y']:\n",
    "    #     # Make test image\n",
    "    #     test_img = generator.create_text_image(char)\n",
    "    #     test_input = test_img.flatten().reshape(1, -1)\n",
    "    #     # Predict\n",
    "    #     prediction = cnn_model.predict(test_input, verbose=0)\n",
    "    #     # print(\"prediction\", prediction)\n",
    "    #     predicted_char = idx_to_char[np.argmax(prediction)]\n",
    "    #     # Result\n",
    "    #     result = \"✅\" if predicted_char == char else \"❌\"\n",
    "    #     print(f\"  {result} '{char}' → '{predicted_char}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bbd2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "def prepare_wine_menu_training_data(vectorizer, n_wines=30, max_distance=200, output_length=5):\n",
    "    \"\"\"\n",
    "    Generate wine menu data and return X, y ready for neural network training.\n",
    "    \n",
    "    Args:\n",
    "        n_wines: Number of wine entries to generate\n",
    "        max_distance: Skip pairs beyond this pixel distance\n",
    "        output_length: TextVectorization sequence length\n",
    "    \n",
    "    Returns:\n",
    "        X: Feature matrix (n_pairs, n_features) ready for NN\n",
    "        y: Labels (n_pairs,) - 1 if same group, 0 if different groups\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Generate wine menu data\n",
    "    vintages = ['2018', '2019', '2020', '2021', '2022', '2023', 'NV']\n",
    "    producers = ['PENFOLDS', 'NAUTILUS', 'CLOUDY BAY', 'WOLF BLASS', 'HARDYS', 'LINDEMANS']\n",
    "    white_varietals = ['Sauvignon Blanc', 'Chardonnay', 'Riesling', 'Pinot Grigio']\n",
    "    red_varietals = ['Shiraz', 'Cabernet Sauvignon', 'Merlot', 'Pinot Noir']\n",
    "    regions = ['Barossa Valley', 'Hunter Valley', 'Margaret River', 'Marlborough NZ']\n",
    "    \n",
    "    col_positions = {'vintage': 50, 'producer': 120, 'varietal': 280, 'region': 450, 'price': 620}\n",
    "    start_y, row_height = 150, 35\n",
    "    \n",
    "    tokens = []\n",
    "    true_groups = []\n",
    "    \n",
    "    # Generate wine tokens\n",
    "    for wine_idx in range(n_wines):\n",
    "        y_pos = start_y + (wine_idx * row_height) + random.randint(-3, 3)\n",
    "        \n",
    "        vintage = random.choice(vintages)\n",
    "        producer = random.choice(producers)\n",
    "        varietal = random.choice(red_varietals if random.choice([True, False]) else white_varietals)\n",
    "        region = random.choice(regions)\n",
    "        price = str(random.randint(25, 150))\n",
    "        \n",
    "        wine_tokens = [\n",
    "            {'text': vintage, 'x': col_positions['vintage'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 11},\n",
    "            {'text': producer, 'x': col_positions['producer'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 13},\n",
    "            {'text': varietal, 'x': col_positions['varietal'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 11},\n",
    "            {'text': region, 'x': col_positions['region'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 9},\n",
    "            {'text': price, 'x': col_positions['price'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 11}\n",
    "        ]\n",
    "        \n",
    "        tokens.extend(wine_tokens)\n",
    "        true_groups.extend([wine_idx] * len(wine_tokens))\n",
    "    \n",
    "    print(f\"Generated {len(tokens)} tokens for {n_wines} wines\")\n",
    "    \n",
    "    # 2. Create TextVectorization\n",
    "    all_texts = [token['text'] for token in tokens]\n",
    "    vectorizer.adapt(all_texts)\n",
    "    text_vectors = vectorizer(all_texts).numpy()\n",
    "    \n",
    "    # 3. Create pairwise features and labels\n",
    "    features = []\n",
    "    labels = []\n",
    "    n_tokens = len(tokens)\n",
    "    \n",
    "    for i in range(n_tokens):\n",
    "        for j in range(i + 1, n_tokens):\n",
    "            token1, token2 = tokens[i], tokens[j]\n",
    "            \n",
    "            # Distance check\n",
    "            x_diff = abs(token1['x'] - token2['x'])\n",
    "            y_diff = abs(token1['y'] - token2['y'])\n",
    "            euclidean_dist = np.sqrt(x_diff**2 + y_diff**2)\n",
    "            \n",
    "            if euclidean_dist > max_distance:\n",
    "                continue\n",
    "            \n",
    "            # Create features\n",
    "            t1_text_vector = text_vectors[i]\n",
    "            t2_text_vector = text_vectors[j]\n",
    "            \n",
    "            spatial_features = [\n",
    "                token1['x'] / 1000.0, token1['y'] / 1000.0, token1['h'] / 100.0,\n",
    "                token2['x'] / 1000.0, token2['y'] / 1000.0, token2['h'] / 100.0,\n",
    "                x_diff / 1000.0, y_diff / 1000.0, euclidean_dist / 1000.0,\n",
    "                float(y_diff < 20), 1.0 if token1['x'] < token2['x'] else -1.0\n",
    "            ]\n",
    "            \n",
    "            pair_features = np.concatenate([t1_text_vector, t2_text_vector, spatial_features])\n",
    "            features.append(pair_features)\n",
    "            \n",
    "            # Create label (1 if same group, 0 if different)\n",
    "            same_group = (true_groups[i] == true_groups[j])\n",
    "            labels.append(int(same_group))\n",
    "    \n",
    "    X = np.array(features)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    print(f\"Created {X.shape[0]} pairs with {X.shape[1]} features each\")\n",
    "    print(f\"Positive pairs (same group): {np.sum(y)} ({np.mean(y):.2%})\")\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    print(\"Ready for training!\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Get training data\n",
    "#     X, y = prepare_wine_menu_training_data(n_wines=20)\n",
    "    \n",
    "#     # Train your model\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(128, input_shape=(X.shape[1],), activation='relu'),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "#         tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "    \n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "#     print(f\"\\nTraining model...\")\n",
    "#     history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, verbose=1)\n",
    "    \n",
    "#     print(f\"\\nTest accuracy: {model.evaluate(X_test, y_test, verbose=0)[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a55fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 tokens for 20 wines\n",
      "Created 885 pairs with 150 features each\n",
      "Labels created: 964\n",
      "Positive pairs (same group): 80 (8.30%)\n",
      "❌ Size mismatch! X: 885, y: 964\n",
      "Check if create_pairwise_features has additional filtering beyond distance\n",
      "✅ Truncated to match: X: (885, 150), y: (885,)\n",
      "Ready for training!\n",
      "\n",
      "Training model...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tr/dev/cellar-ai/.venv/lib/python3.12/site-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6973 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9341 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9329 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9350 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9294 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9186 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.0000e+00 - val_accuracy: 0.9096 - val_loss: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.9096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tr/dev/cellar-ai/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍷 PREDICTING ON REAL MENU DATA\n",
      "==================================================\n",
      "📄 52 tokens extracted\n",
      "🔗 455 pairs created\n",
      "🤖 Making predictions...\n",
      "✅ 0 pairs predicted as SAME GROUP\n",
      "❌ 455 pairs predicted as DIFFERENT GROUP\n",
      "\n",
      "🔍 DETECTED 0 WINE GROUPS\n",
      "==================================================\n",
      "\n",
      "🔍 TOP CONFIDENT PREDICTIONS:\n",
      "------------------------------\n",
      "✅ SAME GROUP (top 5):\n",
      "\n",
      "❌ DIFFERENT GROUP (top 5):\n",
      "   0.000 | '16' ✗ '95'\n",
      "   0.000 | '16' ✗ '19'\n",
      "   0.000 | '16' ✗ 'Toscana Italy'\n",
      "   0.000 | '16' ✗ 'ANTINORI Chianti'\n",
      "   0.000 | '16' ✗ '2020'\n",
      "\n",
      "🎉 DONE! Found 0 wines\n"
     ]
    }
   ],
   "source": [
    "from token_extractor import TokenExtractor\n",
    "from token_enrichor import TokenEnrichor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "  max_tokens=VOCABULARY_MAX_SIZE,\n",
    "  output_sequence_length=1,  # Single token per text\n",
    "  output_mode='int'\n",
    ")\n",
    "\n",
    "\n",
    "def create_pairwise_features(tokens, vectorizer, max_distance=200, same_row_threshold=20, embedding_dim=64):\n",
    "    \"\"\"\n",
    "    Create pairwise features from tokens for neural network training.\n",
    "    \n",
    "    Args:\n",
    "        tokens: List of token dictionaries with keys: 'text', 'x', 'y', 'h', \n",
    "                'is_vintage', 'is_varietal_red', 'is_varietal_white', 'is_price'\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (n_pairs, n_features) ready for NN training\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    features = []\n",
    "\n",
    "    all_texts = [token['text'] for token in tokens]\n",
    "    \n",
    "    vectorizer.adapt(all_texts)\n",
    "\n",
    "    token_ids = vectorizer(all_texts).numpy().flatten()\n",
    "    embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=VOCABULARY_MAX_SIZE,\n",
    "        output_dim=embedding_dim,\n",
    "        mask_zero=True\n",
    "    )\n",
    "\n",
    "    text_embeddings = embedding(token_ids).numpy()\n",
    "\n",
    "    # Create all pairs\n",
    "    for i in range(len(tokens)):\n",
    "      for j in range(i + 1, len(tokens)):\n",
    "        t1, t2 = tokens[i], tokens[j]\n",
    "\n",
    "        # Skip if both tokens are vintage or both are varietals\n",
    "        if 'is_vintage' in t1 and t1['is_vintage'] and 'is_vintage' in t2 and t2['is_vintage']:\n",
    "          continue\n",
    "\n",
    "        # Relationship features (7 features)\n",
    "        x_diff = abs(t1['x'] - t2['x'])\n",
    "        y_diff = abs(t1['y'] - t2['y'])\n",
    "        euclidean_dist = np.sqrt(x_diff**2 + y_diff**2)\n",
    "\n",
    "        if euclidean_dist > max_distance:\n",
    "            continue  # Skip this pair\n",
    "\n",
    "        # Token 1 features (7 features)\n",
    "        t1_features = [\n",
    "            float(t1.get('is_varietal_red', False)),\n",
    "            float(t1.get('is_varietal_white', False)),\n",
    "            float(t1.get('is_price', False)),\n",
    "            float(t1.get('is_vintage', False)),\n",
    "            t1['x'] / 1000.0,  # Normalize coordinates\n",
    "            t1['y'] / 1000.0,\n",
    "            t1['h'] / 100.0,   # Normalize font height\n",
    "        ]\n",
    "        \n",
    "        # Token 2 features (7 features)\n",
    "        t2_features = [\n",
    "            float(t2.get('is_varietal_red', False)),\n",
    "            float(t2.get('is_varietal_white', False)),\n",
    "            float(t2.get('is_price', False)),\n",
    "            float(t2.get('is_vintage', False)),\n",
    "            t2['x'] / 1000.0,\n",
    "            t2['y'] / 1000.0,\n",
    "            t2['h'] / 100.0,\n",
    "        ]\n",
    "        \n",
    "        relationship_features = [\n",
    "            x_diff / 1000.0,                           # X distance (normalized)\n",
    "            y_diff / 1000.0,                           # Y distance (normalized)\n",
    "            euclidean_dist / 1000.0,                   # Euclidean distance (normalized)\n",
    "            float(y_diff < same_row_threshold),        # Same row (boolean)\n",
    "            1.0 if t1['x'] < t2['x'] else -1.0, # Left-right order\n",
    "            abs(t1['h'] - t2['h']) / 100.0,    # Font size difference\n",
    "            min(t1['h'], t2['h']) / max(t1['h'], t2['h'], 1), # Font size ratio\n",
    "            t1['text'] == t2['text'] # same\n",
    "        ]\n",
    "        \n",
    "        t1_embed = text_embeddings[i]  # Shape: (embedding_dim,)\n",
    "        t2_embed = text_embeddings[j]  # Shape: (embedding_dim,)\n",
    "\n",
    "        # Combine all features (21 total)\n",
    "\n",
    "        pair_features = np.concatenate([\n",
    "           t1_embed, \n",
    "           t1_features, \n",
    "           t2_embed, \n",
    "           t2_features,\n",
    "           relationship_features])\n",
    "\n",
    "        features.append(pair_features)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Usage\n",
    "extractor = TokenExtractor(\n",
    "    low_text=0.3,\n",
    "    width_ths=0.4,\n",
    "    height_ths=0.4)\n",
    "\n",
    "enrichor = TokenEnrichor()\n",
    "\n",
    "# Example usage and testing\n",
    "# Generate test data\n",
    "def prepare_wine_menu_training_data(vectorizer, enrichor, n_wines=30):\n",
    "   \"\"\"\n",
    "   Generate wine menu data and return X, y using create_pairwise_features and enrich_token.\n",
    "   \"\"\"\n",
    "   \n",
    "   # 1. Generate wine menu data\n",
    "   vintages = ['2018', '2019', '2020', '2021', '2022', '2023', 'NV']\n",
    "   producers = ['PENFOLDS', 'NAUTILUS', 'CLOUDY BAY', 'WOLF BLASS', 'HARDYS', 'LINDEMANS']\n",
    "   white_varietals = ['Sauvignon Blanc', 'Chardonnay', 'Riesling', 'Pinot Grigio']\n",
    "   red_varietals = ['Shiraz', 'Cabernet Sauvignon', 'Merlot', 'Pinot Noir']\n",
    "   regions = ['Barossa Valley', 'Hunter Valley', 'Margaret River', 'Marlborough NZ']\n",
    "   \n",
    "   col_positions = {'vintage': 50, 'producer': 120, 'varietal': 280, 'region': 450, 'price': 620}\n",
    "   start_y, row_height = 150, 35\n",
    "   \n",
    "   tokens = []\n",
    "   true_groups = []\n",
    "   \n",
    "   # Generate wine tokens\n",
    "   for wine_idx in range(n_wines):\n",
    "       y_pos = start_y + (wine_idx * row_height) + random.randint(-3, 3)\n",
    "       \n",
    "       vintage = random.choice(vintages)\n",
    "       producer = random.choice(producers)\n",
    "       varietal = random.choice(red_varietals if random.choice([True, False]) else white_varietals)\n",
    "       region = random.choice(regions)\n",
    "       price = str(random.randint(25, 150))\n",
    "       \n",
    "       wine_tokens = [\n",
    "           {'text': vintage, 'x': col_positions['vintage'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 11},\n",
    "           {'text': producer, 'x': col_positions['producer'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 13},\n",
    "           {'text': varietal, 'x': col_positions['varietal'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 11},\n",
    "           {'text': region, 'x': col_positions['region'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 9},\n",
    "           {'text': price, 'x': col_positions['price'] + random.randint(-5, 5), 'y': y_pos + random.randint(-2, 2), 'h': 11}\n",
    "       ]\n",
    "       \n",
    "       tokens.extend(wine_tokens)\n",
    "       true_groups.extend([wine_idx] * len(wine_tokens))\n",
    "   \n",
    "   print(f\"Generated {len(tokens)} tokens for {n_wines} wines\")\n",
    "   \n",
    "   # 2. Enrich tokens using your actual enrich_token function\n",
    "   tokens = [enrichor.enrich_token(token) for token in tokens]\n",
    "   \n",
    "   # 3. Use your actual create_pairwise_features function with same parameters\n",
    "   X = create_pairwise_features(\n",
    "       tokens, \n",
    "       vectorizer=vectorizer, \n",
    "       max_distance=200, \n",
    "       same_row_threshold=20, \n",
    "       embedding_dim=64\n",
    "   )\n",
    "   \n",
    "   # 4. Create labels using the EXACT same logic as create_pairwise_features\n",
    "   labels = []\n",
    "   \n",
    "   for i in range(len(tokens)):\n",
    "       for j in range(i + 1, len(tokens)):\n",
    "           token1, token2 = tokens[i], tokens[j]\n",
    "           \n",
    "           # Apply ALL the same filters as create_pairwise_features\n",
    "           x_diff = abs(token1['x'] - token2['x'])\n",
    "           y_diff = abs(token1['y'] - token2['y'])\n",
    "           euclidean_dist = np.sqrt(x_diff**2 + y_diff**2)\n",
    "           \n",
    "           # Same distance filter\n",
    "           if euclidean_dist > 200:  # max_distance\n",
    "               continue\n",
    "               \n",
    "           # Add any other filters that might be in create_pairwise_features\n",
    "           # (check your function for additional filtering conditions)\n",
    "           \n",
    "           # Create label\n",
    "           same_group = (true_groups[i] == true_groups[j])\n",
    "           labels.append(int(same_group))\n",
    "   \n",
    "   y = np.array(labels)\n",
    "   \n",
    "   print(f\"Created {X.shape[0]} pairs with {X.shape[1]} features each\")\n",
    "   print(f\"Labels created: {len(y)}\")\n",
    "   print(f\"Positive pairs (same group): {np.sum(y)} ({np.mean(y):.2%})\")\n",
    "   \n",
    "   # Verify sizes match\n",
    "   if X.shape[0] != len(y):\n",
    "       print(f\"❌ Size mismatch! X: {X.shape[0]}, y: {len(y)}\")\n",
    "       print(\"Check if create_pairwise_features has additional filtering beyond distance\")\n",
    "       # Truncate to match\n",
    "       min_size = min(X.shape[0], len(y))\n",
    "       X = X[:min_size]\n",
    "       y = y[:min_size]\n",
    "       print(f\"✅ Truncated to match: X: {X.shape}, y: {y.shape}\")\n",
    "   else:\n",
    "       print(f\"✅ Perfect match! X: {X.shape}, y: {y.shape}\")\n",
    "   \n",
    "   print(\"Ready for training!\")\n",
    "   \n",
    "   return X, y\n",
    "\n",
    "# Now train with the exact same pipeline as testing\n",
    "X, y = prepare_wine_menu_training_data(vectorizer=vectorizer, enrichor=enrichor, n_wines=20)\n",
    "\n",
    "\n",
    "# Train your model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Input(shape=(X.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'), \n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nTraining model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "print(f\"\\nTraining model...\")\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, verbose=1)\n",
    "\n",
    "print(f\"\\nTest accuracy: {model.evaluate(X_test, y_test, verbose=0)[1]:.4f}\")\n",
    "\n",
    "# test\n",
    "tokens = extractor.extract_tokens('data/menus/menu_test.png')\n",
    "\n",
    "tokens = [enrichor.enrich_token(token) for token in tokens]\n",
    "\n",
    "X = create_pairwise_features(tokens, vectorizer=vectorizer)\n",
    "# You already have:\n",
    "# tokens = extractor.extract_tokens('data/menus/menu_test.png')\n",
    "# tokens = [enrich_token(token) for token in tokens]\n",
    "# X = create_pairwise_features(tokens)\n",
    "\n",
    "print(\"🍷 PREDICTING ON REAL MENU DATA\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📄 {len(tokens)} tokens extracted\")\n",
    "print(f\"🔗 {X.shape[0]} pairs created\")\n",
    "print(f\"🤖 Making predictions...\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X, verbose=0).flatten()\n",
    "\n",
    "# Show prediction stats\n",
    "same_group = np.sum(predictions > 0.5)\n",
    "different_group = np.sum(predictions <= 0.5)\n",
    "print(f\"✅ {same_group} pairs predicted as SAME GROUP\")\n",
    "print(f\"❌ {different_group} pairs predicted as DIFFERENT GROUP\")\n",
    "\n",
    "# Create adjacency matrix for grouping\n",
    "n_tokens = len(tokens)\n",
    "adjacency = np.zeros((n_tokens, n_tokens))\n",
    "\n",
    "# Fill adjacency matrix from predictions\n",
    "pair_idx = 0\n",
    "for i in range(n_tokens):\n",
    "   for j in range(i + 1, n_tokens):\n",
    "       # Skip if pair was filtered out during feature creation\n",
    "       if pair_idx < len(predictions) and predictions[pair_idx] > 0.5:\n",
    "           adjacency[i][j] = 1\n",
    "           adjacency[j][i] = 1\n",
    "       if pair_idx < len(predictions):\n",
    "           pair_idx += 1\n",
    "\n",
    "# Find connected components (groups)\n",
    "visited = [False] * n_tokens\n",
    "groups = []\n",
    "\n",
    "def dfs(node, current_group):\n",
    "   visited[node] = True\n",
    "   current_group.append(node)\n",
    "   for neighbor in range(n_tokens):\n",
    "       if adjacency[node][neighbor] == 1 and not visited[neighbor]:\n",
    "           dfs(neighbor, current_group)\n",
    "\n",
    "for i in range(n_tokens):\n",
    "   if not visited[i]:\n",
    "       current_group = []\n",
    "       dfs(i, current_group)\n",
    "       groups.append(current_group)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n🔍 DETECTED {len([g for g in groups if len(g) > 1])} WINE GROUPS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for group_idx, group in enumerate(groups):\n",
    "   if len(group) == 1:\n",
    "       continue  # Skip single tokens\n",
    "       \n",
    "   print(f\"\\n🍷 WINE {group_idx + 1}:\")\n",
    "   \n",
    "   # Sort tokens by x position (left to right)\n",
    "   group_tokens = [tokens[i] for i in group]\n",
    "   group_tokens.sort(key=lambda x: x['x'])\n",
    "   \n",
    "   wine_text = []\n",
    "   for token in group_tokens:\n",
    "       text = token['text']\n",
    "       if token.get('is_vintage'):\n",
    "           text += \" 🗓️\"\n",
    "       elif token.get('is_varietal_red'):\n",
    "           text += \" 🍷\"  \n",
    "       elif token.get('is_varietal_white'):\n",
    "           text += \" 🥂\"\n",
    "       elif token.get('is_price'):\n",
    "           text += \" 💰\"\n",
    "       wine_text.append(text)\n",
    "   \n",
    "   print(f\"   {' | '.join(wine_text)}\")\n",
    "\n",
    "# Show top confident predictions\n",
    "print(f\"\\n🔍 TOP CONFIDENT PREDICTIONS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Get pair info for top predictions\n",
    "pair_info = []\n",
    "pair_idx = 0\n",
    "for i in range(n_tokens):\n",
    "   for j in range(i + 1, n_tokens):\n",
    "       if pair_idx < len(predictions):\n",
    "           pair_info.append((i, j, predictions[pair_idx]))\n",
    "           pair_idx += 1\n",
    "\n",
    "# Sort by confidence\n",
    "pair_info.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"✅ SAME GROUP (top 5):\")\n",
    "count = 0\n",
    "for i, j, conf in pair_info:\n",
    "   if conf > 0.5 and count < 5:\n",
    "       print(f\"   {conf:.3f} | '{tokens[i]['text']}' ↔ '{tokens[j]['text']}'\")\n",
    "       count += 1\n",
    "\n",
    "print(\"\\n❌ DIFFERENT GROUP (top 5):\")\n",
    "count = 0\n",
    "for i, j, conf in reversed(pair_info[-10:]):\n",
    "   if conf < 0.5 and count < 5:\n",
    "       print(f\"   {conf:.3f} | '{tokens[i]['text']}' ✗ '{tokens[j]['text']}'\")\n",
    "       count += 1\n",
    "\n",
    "print(f\"\\n🎉 DONE! Found {len([g for g in groups if len(g) > 1])} wines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7ade9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a520dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
