{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a79c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 14:51:51.061262: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-14 14:51:51.210837: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752468711.266071  912927 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752468711.283230  912927 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752468711.422002  912927 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752468711.422041  912927 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752468711.422044  912927 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752468711.422046  912927 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-14 14:51:51.438696: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍷 WINE OCR LEARNING LAB - STUDENT VERSION\n",
      "Your mission: Fill in the missing code to build a complete system!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from text_generator import TextGenerator\n",
    "from config.wine import RED_VARIETALS, WHITE_VARIETALS, VARIETAL_ABBREVIATIONS, COUNTRIES\n",
    "from robust_text_generator import RobustTextImageGenerator\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "print(\"🍷 WINE OCR LEARNING LAB - STUDENT VERSION\")\n",
    "print(\"Your mission: Fill in the missing code to build a complete system!\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONSTS\n",
    "# =============================================================================\n",
    "\n",
    "VOCABULARY_MAX_SIZE = 100000  # Adjust as needed\n",
    "\n",
    "MENU_CHARACTERS = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz.,-*'&$%\"\n",
    "\n",
    "MENU_GROUPING_MAX_DISTANCE = 200\n",
    "#(\n",
    "    \n",
    "#     \"0123456789\" +           # Years, prices\n",
    "#     \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" +  # Wine names (caps)\n",
    "#     \"abcdefghijklmnopqrstuvwxyz\" +  # Wine names (lowercase)\n",
    "#     \" .,-*'&$%\"                 # Punctuation\n",
    "# )\n",
    "\n",
    "\n",
    "char_to_idx = {char: idx for idx, char in enumerate(MENU_CHARACTERS)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(MENU_CHARACTERS)}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a55fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PNG -> Wine Entries\n",
    "\n",
    "from menu_token_extractor import TokenExtractor\n",
    "from menu_token_enrichor import TokenEnrichor\n",
    "\n",
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "  max_tokens=VOCABULARY_MAX_SIZE,\n",
    "  output_sequence_length=1,  # Single token per text\n",
    "  output_mode='int'\n",
    ")\n",
    "\n",
    "extractor = TokenExtractor(\n",
    "    low_text=0.3,\n",
    "    width_ths=0.4,\n",
    "    height_ths=0.4)\n",
    "\n",
    "enrichor = TokenEnrichor(red_varietals=RED_VARIETALS,\n",
    "                        white_varietals=WHITE_VARIETALS,\n",
    "                        varietal_abbreviations=VARIETAL_ABBREVIATIONS,\n",
    "                        countries=COUNTRIES)\n",
    "\n",
    "def create_pairwise_features(tokens, vectorizer, max_distance=MENU_GROUPING_MAX_DISTANCE, same_row_threshold=20, embedding_dim=64):\n",
    "    \"\"\"\n",
    "    Create pairwise features from tokens for neural network training.\n",
    "    \n",
    "    Args:\n",
    "        tokens: List of token dictionaries with keys: 'text', 'x', 'y', 'h', \n",
    "                'is_vintage', 'is_varietal_red', 'is_varietal_white', 'is_price'\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (n_pairs, n_features) ready for NN training\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    features = []\n",
    "\n",
    "    all_texts = [token['text'] for token in tokens]\n",
    "    \n",
    "    vectorizer.adapt(all_texts)\n",
    "\n",
    "    token_ids = vectorizer(all_texts).numpy().flatten()\n",
    "    embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=VOCABULARY_MAX_SIZE,\n",
    "        output_dim=embedding_dim,\n",
    "        mask_zero=True\n",
    "    )\n",
    "\n",
    "    text_embeddings = embedding(token_ids).numpy()\n",
    "\n",
    "    # Create all pairs\n",
    "    for i in range(len(tokens)):\n",
    "      for j in range(i + 1, len(tokens)):\n",
    "        t1, t2 = tokens[i], tokens[j]\n",
    "\n",
    "        # Skip if both tokens are vintage or both are varietals\n",
    "        if 'is_vintage' in t1 and t1['is_vintage'] and 'is_vintage' in t2 and t2['is_vintage']:\n",
    "          continue\n",
    "\n",
    "        # Relationship features (7 features)\n",
    "        x_diff = abs(t1['x'] - t2['x'])\n",
    "        y_diff = abs(t1['y'] - t2['y'])\n",
    "        euclidean_dist = np.sqrt(x_diff**2 + y_diff**2)\n",
    "\n",
    "        # if euclidean_dist > max_distance:\n",
    "        #     continue  # Skip this pair\n",
    "\n",
    "        # Token 1 features (7 features)\n",
    "        t1_features = [\n",
    "            \n",
    "            t1['text'],\n",
    "\n",
    "            float(t1.get('is_varietal_red', False)),\n",
    "            float(t1.get('is_varietal_white', False)),\n",
    "            float(t1.get('is_price', False)),\n",
    "            float(t1.get('is_vintage', False)),\n",
    "            float(t1.get('is_region', False)),\n",
    "            float(t1.get('is_country', False)),\n",
    "\n",
    "            t1['x'] / 1000.0,  # Normalize coordinates\n",
    "            t1['y'] / 1000.0,\n",
    "            t1['h'] / 100.0,   # Normalize font height\n",
    "        ]\n",
    "        \n",
    "        # Token 2 features (7 features)\n",
    "        t2_features = [\n",
    "            \n",
    "            t2['text'],\n",
    "\n",
    "            float(t2.get('is_varietal_red', False)),\n",
    "            float(t2.get('is_varietal_white', False)),\n",
    "            float(t2.get('is_price', False)),\n",
    "            float(t2.get('is_vintage', False)),\n",
    "            float(t2.get('is_region', False)),\n",
    "            float(t2.get('is_country', False)),\n",
    "\n",
    "            t2['x'] / 1000.0,\n",
    "            t2['y'] / 1000.0,\n",
    "            t2['h'] / 100.0,\n",
    "        ]\n",
    "        \n",
    "        relationship_features = [\n",
    "            x_diff / 1000.0,                           # X distance (normalized)\n",
    "            y_diff / 1000.0,                           # Y distance (normalized)\n",
    "            euclidean_dist / 1000.0,                   # Euclidean distance (normalized)\n",
    "            float(y_diff < same_row_threshold),        # Same row (boolean)\n",
    "            1.0 if t1['x'] < t2['x'] else -1.0, # Left-right order\n",
    "            abs(t1['h'] - t2['h']) / 100.0,    # Font size difference\n",
    "            min(t1['h'], t2['h']) / max(t1['h'], t2['h'], 1), # Font size ratio\n",
    "            float(t1['text'] == t2['text']) # same\n",
    "        ]\n",
    "        \n",
    "        t1_embed = text_embeddings[i]  # Shape: (embedding_dim,)\n",
    "        t2_embed = text_embeddings[j]  # Shape: (embedding_dim,)\n",
    "\n",
    "        # Combine all features (21 total)\n",
    "\n",
    "        pair_features = np.concatenate([\n",
    "          #  t1_embed, \n",
    "           t1_features, \n",
    "          #  t2_embed, \n",
    "           t2_features,\n",
    "           relationship_features])\n",
    "\n",
    "        features.append(pair_features)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Usage\n",
    "\n",
    "def pairwise_predictions_to_wine_entries(tokens, predictions, threshold=0.5):\n",
    "   \"\"\"Convert pairwise predictions to wine entries DataFrame\"\"\"\n",
    "   import pandas as pd\n",
    "   import numpy as np\n",
    "   \n",
    "   n_tokens = len(tokens)\n",
    "   adjacency = np.zeros((n_tokens, n_tokens))\n",
    "   \n",
    "   # Fill adjacency matrix\n",
    "   pair_idx = 0\n",
    "   for i in range(n_tokens):\n",
    "       for j in range(i + 1, n_tokens):\n",
    "           t1, t2 = tokens[i], tokens[j]\n",
    "           \n",
    "           if t1.get('is_vintage', False) and t2.get('is_vintage', False):\n",
    "               continue\n",
    "           \n",
    "           x_diff = abs(t1['x'] - t2['x'])\n",
    "           y_diff = abs(t1['y'] - t2['y'])\n",
    "           euclidean_dist = np.sqrt(x_diff**2 + y_diff**2)\n",
    "           \n",
    "           if euclidean_dist > 800:\n",
    "               continue\n",
    "           \n",
    "           if pair_idx < len(predictions) and predictions[pair_idx] > threshold:\n",
    "               adjacency[i][j] = 1\n",
    "               adjacency[j][i] = 1\n",
    "           \n",
    "           pair_idx += 1\n",
    "   \n",
    "   # Find groups\n",
    "   visited = [False] * n_tokens\n",
    "   groups = []\n",
    "   \n",
    "   def dfs(node, current_group):\n",
    "       visited[node] = True\n",
    "       current_group.append(node)\n",
    "       for neighbor in range(n_tokens):\n",
    "           if adjacency[node][neighbor] == 1 and not visited[neighbor]:\n",
    "               dfs(neighbor, current_group)\n",
    "   \n",
    "   for i in range(n_tokens):\n",
    "       if not visited[i]:\n",
    "           current_group = []\n",
    "           dfs(i, current_group)\n",
    "           groups.append(current_group)\n",
    "   \n",
    "   # Extract wine entries\n",
    "   wine_entries = []\n",
    "   for group_indices in groups:\n",
    "       if len(group_indices) == 1:\n",
    "           continue\n",
    "           \n",
    "       group_tokens = [tokens[i] for i in group_indices]\n",
    "       group_tokens.sort(key=lambda x: x['x'])\n",
    "       \n",
    "       wine_entry = {\n",
    "           'vintage': '', 'country': '', 'region': '', 'type': '', 'varietal': '',\n",
    "           'glass_price': '', 'bottle_price': '', 'description': '', 'other_texts': []\n",
    "       }\n",
    "       \n",
    "       prices = []\n",
    "       for token in group_tokens:\n",
    "           text = token['text']\n",
    "           \n",
    "           if token.get('is_vintage'):\n",
    "               wine_entry['vintage'] = text\n",
    "           elif token.get('is_price'):\n",
    "               prices.append(int(text) if text.isdigit() else 0)\n",
    "           elif token.get('is_varietal_red'):\n",
    "               wine_entry['varietal'] = text\n",
    "               wine_entry['type'] = 'red'\n",
    "           elif token.get('is_varietal_white'):\n",
    "               wine_entry['varietal'] = text\n",
    "               wine_entry['type'] = 'white'\n",
    "           else:\n",
    "               wine_entry['other_texts'].append(text)\n",
    "       \n",
    "       if len(prices) >= 2:\n",
    "           prices.sort()\n",
    "           wine_entry['glass_price'] = str(prices[0])\n",
    "           wine_entry['bottle_price'] = str(prices[-1])\n",
    "       elif len(prices) == 1:\n",
    "           wine_entry['bottle_price'] = str(prices[0])\n",
    "       \n",
    "       wine_entries.append(wine_entry)\n",
    "   \n",
    "   return pd.DataFrame(wine_entries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd7ec81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MENU_TRAINING_1_COL_GROUPS = [\n",
    "   # Group 0: Noise and headers\n",
    "   [\n",
    "       {'text': 'WINE LIST', 'x': 350, 'y': 85, 'h': 32},\n",
    "       {'text': 'RED WINES', 'x': 125, 'y': 125, 'h': 24},\n",
    "       {'text': 'WHITE WINES', 'x': 125, 'y': 380, 'h': 24},\n",
    "       {'text': 'Vintage', 'x': 52, 'y': 155, 'h': 14},\n",
    "       {'text': 'Producer', 'x': 148, 'y': 155, 'h': 14},\n",
    "       {'text': 'Varietal', 'x': 285, 'y': 155, 'h': 14},\n",
    "       {'text': 'Region', 'x': 425, 'y': 155, 'h': 14},\n",
    "       {'text': 'Price', 'x': 612, 'y': 155, 'h': 14}\n",
    "   ],\n",
    "   \n",
    "   # Group 1: Wine 1\n",
    "   [\n",
    "       {'text': '2023', 'x': 52, 'y': 182, 'h': 18},\n",
    "       {'text': 'PENFOLDS', 'x': 148, 'y': 182, 'h': 20},\n",
    "       {'text': 'Shiraz', 'x': 285, 'y': 182, 'h': 18},\n",
    "       {'text': 'Barossa Valley', 'x': 425, 'y': 182, 'h': 16},\n",
    "       {'text': '85', 'x': 612, 'y': 182, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 2: Wine 2\n",
    "   [\n",
    "       {'text': '2022', 'x': 52, 'y': 218, 'h': 18},\n",
    "       {'text': 'NAUTILUS', 'x': 148, 'y': 218, 'h': 20},\n",
    "       {'text': 'Sauvignon Blanc', 'x': 285, 'y': 218, 'h': 18},\n",
    "       {'text': 'Marlborough NZ', 'x': 425, 'y': 218, 'h': 16},\n",
    "       {'text': '65', 'x': 612, 'y': 218, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 3: Wine 3\n",
    "   [\n",
    "       {'text': '2021', 'x': 52, 'y': 254, 'h': 18},\n",
    "       {'text': 'CLOUDY BAY', 'x': 148, 'y': 254, 'h': 20},\n",
    "       {'text': 'Chardonnay', 'x': 285, 'y': 254, 'h': 18},\n",
    "       {'text': 'Hawkes Bay NZ', 'x': 425, 'y': 254, 'h': 16},\n",
    "       {'text': '72', 'x': 612, 'y': 254, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 4: Wine 4\n",
    "   [\n",
    "       {'text': '2020', 'x': 52, 'y': 290, 'h': 18},\n",
    "       {'text': 'WOLF BLASS', 'x': 148, 'y': 290, 'h': 20},\n",
    "       {'text': 'Cabernet Sauvignon', 'x': 285, 'y': 290, 'h': 18},\n",
    "       {'text': 'South Australia', 'x': 425, 'y': 290, 'h': 16},\n",
    "       {'text': '95', 'x': 612, 'y': 290, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 5: Wine 5\n",
    "   [\n",
    "       {'text': 'NV', 'x': 52, 'y': 326, 'h': 18},\n",
    "       {'text': 'YELLOWTAIL', 'x': 148, 'y': 326, 'h': 20},\n",
    "       {'text': 'Pinot Noir', 'x': 285, 'y': 326, 'h': 18},\n",
    "       {'text': 'Victoria', 'x': 425, 'y': 326, 'h': 16},\n",
    "       {'text': '42', 'x': 612, 'y': 326, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 6: Wine 6\n",
    "   [\n",
    "       {'text': '2019', 'x': 45, 'y': 362, 'h': 17},\n",
    "       {'text': 'HARDYS', 'x': 145, 'y': 362, 'h': 19},\n",
    "       {'text': 'Merlot', 'x': 288, 'y': 362, 'h': 17},\n",
    "       {'text': 'McLaren Vale', 'x': 428, 'y': 362, 'h': 15},\n",
    "       {'text': '78', 'x': 615, 'y': 362, 'h': 17}\n",
    "   ],\n",
    "   \n",
    "   # Group 7: Wine 7\n",
    "   [\n",
    "       {'text': '2024', 'x': 55, 'y': 398, 'h': 18},\n",
    "       {'text': 'JACOB\\'S CREEK', 'x': 150, 'y': 398, 'h': 20},\n",
    "       {'text': 'Riesling', 'x': 282, 'y': 398, 'h': 18},\n",
    "       {'text': 'Eden Valley', 'x': 422, 'y': 398, 'h': 16},\n",
    "       {'text': '55', 'x': 610, 'y': 398, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 8: Wine 8\n",
    "   [\n",
    "       {'text': '2018', 'x': 48, 'y': 434, 'h': 19},\n",
    "       {'text': 'WYNNS', 'x': 152, 'y': 434, 'h': 21},\n",
    "       {'text': 'Cabernet Sauvignon', 'x': 290, 'y': 434, 'h': 19},\n",
    "       {'text': 'Coonawarra', 'x': 430, 'y': 434, 'h': 17},\n",
    "       {'text': '120', 'x': 608, 'y': 434, 'h': 19}\n",
    "   ],\n",
    "   \n",
    "   # Group 9: Wine 9\n",
    "   [\n",
    "       {'text': '2023', 'x': 50, 'y': 470, 'h': 18},\n",
    "       {'text': 'MCGUIGAN', 'x': 146, 'y': 470, 'h': 20},\n",
    "       {'text': 'Semillon', 'x': 286, 'y': 470, 'h': 18},\n",
    "       {'text': 'Hunter Valley', 'x': 426, 'y': 470, 'h': 16},\n",
    "       {'text': '48', 'x': 614, 'y': 470, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 10: Wine 10\n",
    "   [\n",
    "       {'text': '2022', 'x': 53, 'y': 506, 'h': 17},\n",
    "       {'text': 'TYRRELL\\'S', 'x': 149, 'y': 506, 'h': 19},\n",
    "       {'text': 'Gewürztraminer', 'x': 283, 'y': 506, 'h': 17},\n",
    "       {'text': 'Adelaide Hills', 'x': 423, 'y': 506, 'h': 15},\n",
    "       {'text': '62', 'x': 612, 'y': 506, 'h': 17}\n",
    "   ],\n",
    "   \n",
    "   # Group 11: Wine 11\n",
    "   [\n",
    "       {'text': '2021', 'x': 47, 'y': 542, 'h': 18},\n",
    "       {'text': 'YALUMBA', 'x': 151, 'y': 542, 'h': 20},\n",
    "       {'text': 'Viognier', 'x': 287, 'y': 542, 'h': 18},\n",
    "       {'text': 'Eden Valley', 'x': 427, 'y': 542, 'h': 16},\n",
    "       {'text': '88', 'x': 611, 'y': 542, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 12: Wine 12\n",
    "   [\n",
    "       {'text': '2020', 'x': 54, 'y': 578, 'h': 19},\n",
    "       {'text': 'CAPE MENTELLE', 'x': 147, 'y': 578, 'h': 21},\n",
    "       {'text': 'Cabernet Merlot', 'x': 285, 'y': 578, 'h': 19},\n",
    "       {'text': 'Margaret River', 'x': 425, 'y': 578, 'h': 17},\n",
    "       {'text': '135', 'x': 609, 'y': 578, 'h': 19}\n",
    "   ],\n",
    "   \n",
    "   # Group 13: Wine 13\n",
    "   [\n",
    "       {'text': 'NV', 'x': 51, 'y': 614, 'h': 18},\n",
    "       {'text': 'LEEUWIN', 'x': 153, 'y': 614, 'h': 20},\n",
    "       {'text': 'Moscato', 'x': 289, 'y': 614, 'h': 18},\n",
    "       {'text': 'Margaret River', 'x': 429, 'y': 614, 'h': 16},\n",
    "       {'text': '45', 'x': 613, 'y': 614, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 14: Wine 14\n",
    "   [\n",
    "       {'text': '2019', 'x': 49, 'y': 650, 'h': 17},\n",
    "       {'text': 'VASSE FELIX', 'x': 148, 'y': 650, 'h': 19},\n",
    "       {'text': 'Pinot Grigio', 'x': 284, 'y': 650, 'h': 17},\n",
    "       {'text': 'Margaret River', 'x': 424, 'y': 650, 'h': 15},\n",
    "       {'text': '75', 'x': 615, 'y': 650, 'h': 17}\n",
    "   ],\n",
    "   \n",
    "   # Group 15: Wine 15\n",
    "   [\n",
    "       {'text': '2023', 'x': 52, 'y': 686, 'h': 18},\n",
    "       {'text': 'CULLEN', 'x': 150, 'y': 686, 'h': 20},\n",
    "       {'text': 'Sauvignon Blanc', 'x': 282, 'y': 686, 'h': 18},\n",
    "       {'text': 'Margaret River', 'x': 422, 'y': 686, 'h': 16},\n",
    "       {'text': '92', 'x': 610, 'y': 686, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 16: Wine 16\n",
    "   [\n",
    "       {'text': '2018', 'x': 46, 'y': 722, 'h': 19},\n",
    "       {'text': 'HENSCHKE', 'x': 152, 'y': 722, 'h': 21},\n",
    "       {'text': 'Shiraz', 'x': 288, 'y': 722, 'h': 19},\n",
    "       {'text': 'Eden Valley', 'x': 428, 'y': 722, 'h': 17},\n",
    "       {'text': '180', 'x': 607, 'y': 722, 'h': 19}\n",
    "   ],\n",
    "   \n",
    "   # Group 17: Wine 17\n",
    "   [\n",
    "       {'text': '2022', 'x': 55, 'y': 758, 'h': 18},\n",
    "       {'text': 'TORBRECK', 'x': 149, 'y': 758, 'h': 20},\n",
    "       {'text': 'Grenache', 'x': 286, 'y': 758, 'h': 18},\n",
    "       {'text': 'Barossa Valley', 'x': 426, 'y': 758, 'h': 16},\n",
    "       {'text': '110', 'x': 612, 'y': 758, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 18: Wine 18\n",
    "   [\n",
    "       {'text': '2021', 'x': 48, 'y': 794, 'h': 17},\n",
    "       {'text': 'CLARENDON HILLS', 'x': 145, 'y': 794, 'h': 19},\n",
    "       {'text': 'Syrah', 'x': 291, 'y': 794, 'h': 17},\n",
    "       {'text': 'McLaren Vale', 'x': 431, 'y': 794, 'h': 15},\n",
    "       {'text': '165', 'x': 611, 'y': 794, 'h': 17}\n",
    "   ],\n",
    "   \n",
    "   # Group 19: Wine 19\n",
    "   [\n",
    "       {'text': '2020', 'x': 51, 'y': 830, 'h': 18},\n",
    "       {'text': 'KATNOOK', 'x': 147, 'y': 830, 'h': 20},\n",
    "       {'text': 'Cabernet Sauvignon', 'x': 284, 'y': 830, 'h': 18},\n",
    "       {'text': 'Coonawarra', 'x': 427, 'y': 830, 'h': 16},\n",
    "       {'text': '98', 'x': 613, 'y': 830, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 20: Wine 20\n",
    "   [\n",
    "       {'text': '2019', 'x': 53, 'y': 866, 'h': 19},\n",
    "       {'text': 'PETALUMA', 'x': 151, 'y': 866, 'h': 21},\n",
    "       {'text': 'Chardonnay', 'x': 287, 'y': 866, 'h': 19},\n",
    "       {'text': 'Adelaide Hills', 'x': 429, 'y': 866, 'h': 17},\n",
    "       {'text': '125', 'x': 609, 'y': 866, 'h': 19}\n",
    "   ],\n",
    "   \n",
    "   # Group 21: Wine 21\n",
    "   [\n",
    "       {'text': 'NV', 'x': 47, 'y': 902, 'h': 18},\n",
    "       {'text': 'MOUNTADAM', 'x': 149, 'y': 902, 'h': 20},\n",
    "       {'text': 'Pinot Noir', 'x': 285, 'y': 902, 'h': 18},\n",
    "       {'text': 'Eden Valley', 'x': 425, 'y': 902, 'h': 16},\n",
    "       {'text': '85', 'x': 615, 'y': 902, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 22: Wine 22\n",
    "   [\n",
    "       {'text': '2023', 'x': 50, 'y': 938, 'h': 17},\n",
    "       {'text': 'GROSSET', 'x': 153, 'y': 938, 'h': 19},\n",
    "       {'text': 'Riesling', 'x': 289, 'y': 938, 'h': 17},\n",
    "       {'text': 'Clare Valley', 'x': 423, 'y': 938, 'h': 15},\n",
    "       {'text': '72', 'x': 611, 'y': 938, 'h': 17}\n",
    "   ],\n",
    "   \n",
    "   # Group 23: Wine 23\n",
    "   [\n",
    "       {'text': '2022', 'x': 54, 'y': 974, 'h': 18},\n",
    "       {'text': 'PIKE', 'x': 146, 'y': 974, 'h': 20},\n",
    "       {'text': 'Chenin Blanc', 'x': 283, 'y': 974, 'h': 18},\n",
    "       {'text': 'Clare Valley', 'x': 427, 'y': 974, 'h': 16},\n",
    "       {'text': '58', 'x': 613, 'y': 974, 'h': 18}\n",
    "   ],\n",
    "   \n",
    "   # Group 24: Wine 24\n",
    "   [\n",
    "       {'text': '2021', 'x': 48, 'y': 1010, 'h': 19},\n",
    "       {'text': 'ELDERTON', 'x': 150, 'y': 1010, 'h': 21},\n",
    "       {'text': 'Shiraz', 'x': 286, 'y': 1010, 'h': 19},\n",
    "       {'text': 'Barossa Valley', 'x': 430, 'y': 1010, 'h': 17},\n",
    "       {'text': '145', 'x': 608, 'y': 1010, 'h': 19}\n",
    "   ],\n",
    "   \n",
    "   # Group 25: Wine 25\n",
    "   [\n",
    "       {'text': '2018', 'x': 52, 'y': 1046, 'h': 18},\n",
    "       {'text': 'CHATEAU TANUNDA', 'x': 144, 'y': 1046, 'h': 20},\n",
    "       {'text': 'Grenache', 'x': 288, 'y': 1046, 'h': 18},\n",
    "       {'text': 'Barossa Valley', 'x': 426, 'y': 1046, 'h': 16},\n",
    "       {'text': '88', 'x': 612, 'y': 1046, 'h': 18}\n",
    "   ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c14ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Flattened to 133 tokens\n",
      "✅ Tokens enriched\n",
      "🔗 Created 8547 pairs with 28 features\n",
      "📊 Labels created: 8547\n",
      "   Positive pairs (same wine): 250 (2.93%)\n",
      "   Negative pairs: 8297\n",
      "✅ X shape: (8547, 28), y shape: (8547,)\n",
      "🍷 TRAINING DATA - X_train & y_train:\n",
      "==================================================\n",
      "X_train shape: (6837, 28)\n",
      "y_train shape: (6837,)\n",
      "Positive samples: 205 (3.0%)\n",
      "Negative samples: 6632 (97.0%)\n",
      "\n",
      "First 10 y_train labels:\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "First 5 X_train feature vectors (first 10 features only):\n",
      "Sample 0: ['Cabernet Sauvignon' '1.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.285' '0.29'\n",
      " '0.18']... (label: 0)\n",
      "Sample 1: ['Pinot Grigio' '0.0' '1.0' '0.0' '0.0' '0.0' '0.0' '0.284' '0.65' '0.17']... (label: 0)\n",
      "Sample 2: ['Sauvignon Blanc' '0.0' '1.0' '0.0' '0.0' '0.0' '0.0' '0.282' '0.686'\n",
      " '0.18']... (label: 0)\n",
      "Sample 3: ['YELLOWTAIL' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.148' '0.326' '0.2']... (label: 0)\n",
      "Sample 4: ['eden valley' '0.0' '0.0' '0.0' '0.0' '1.0' '0.0' '0.427' '0.542' '0.16']... (label: 0)\n",
      "\n",
      "X_train feature stats:\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'minimum' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUFuncTypeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     74\u001b[39m    \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train[i][:\u001b[32m10\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m... (label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mX_train feature stats:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Min: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Max: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.max()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/cellar-ai/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:49\u001b[39m, in \u001b[36m_amin\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     48\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUFuncTypeError\u001b[39m: ufunc 'minimum' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> None"
     ]
    }
   ],
   "source": [
    "\n",
    "# Flatten for processing and keep track of original groups\n",
    "tokens = []\n",
    "original_groups = []\n",
    "for group_idx, group in enumerate(MENU_TRAINING_1_COL_GROUPS):\n",
    "    for token in group:\n",
    "        tokens.append(token)\n",
    "        original_groups.append(group_idx)\n",
    "\n",
    "print(f\"🔄 Flattened to {len(tokens)} tokens\")\n",
    "\n",
    "# Enrich tokens\n",
    "tokens = [enrichor.enrich_token(token) for token in tokens]\n",
    "print(f\"✅ Tokens enriched\")\n",
    "\n",
    "# Create features\n",
    "X = create_pairwise_features(tokens, vectorizer=vectorizer)\n",
    "print(f\"🔗 Created {X.shape[0]} pairs with {X.shape[1]} features\")\n",
    "\n",
    "# Create labels with EXACT same filtering as create_pairwise_features\n",
    "labels = []\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    for j in range(i + 1, len(tokens)):\n",
    "        t1, t2 = tokens[i], tokens[j]\n",
    "        \n",
    "        # Apply SAME filters as create_pairwise_features\n",
    "        \n",
    "        # Skip if both tokens are vintage\n",
    "        if t1.get('is_vintage', False) and t2.get('is_vintage', False):\n",
    "            continue\n",
    "            \n",
    "        # Distance check\n",
    "        x_diff = abs(t1['x'] - t2['x'])\n",
    "        y_diff = abs(t1['y'] - t2['y'])\n",
    "        # euclidean_dist = np.sqrt(x_diff**2 + y_diff**2)\n",
    "        \n",
    "        # if euclidean_dist > MENU_GROUPING_MAX_DISTANCE:  # Same max_distance as create_pairwise_features\n",
    "        #     continue\n",
    "            \n",
    "        # This pair passed all filters, create label\n",
    "        group_i = original_groups[i]\n",
    "        group_j = original_groups[j]\n",
    "        \n",
    "        same_group = (group_i == group_j and group_i > 0 and group_j > 0)\n",
    "        labels.append(int(same_group))\n",
    "\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"📊 Labels created: {len(y)}\")\n",
    "print(f\"   Positive pairs (same wine): {np.sum(y)} ({np.mean(y):.2%})\")\n",
    "print(f\"   Negative pairs: {len(y) - np.sum(y)}\")\n",
    "\n",
    "assert X.shape[0] == len(y), f\"Perfect match! X: {X.shape[0]}, y: {len(y)}\"\n",
    "print(f\"✅ X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "# Train model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"🍷 TRAINING DATA - X_train & y_train:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"Positive samples: {np.sum(y_train == 1)} ({np.mean(y_train == 1):.1%})\")\n",
    "print(f\"Negative samples: {np.sum(y_train == 0)} ({np.mean(y_train == 0):.1%})\")\n",
    "\n",
    "print(f\"\\nFirst 10 y_train labels:\")\n",
    "print(y_train[:10])\n",
    "\n",
    "print(f\"\\nFirst 5 X_train feature vectors (first 10 features only):\")\n",
    "for i in range(min(5, len(X_train))):\n",
    "   print(f\"Sample {i}: {X_train[i][:10]}... (label: {y_train[i]})\")\n",
    "\n",
    "print(f\"\\nX_train feature stats:\")\n",
    "print(f\"  Min: {X_train.min():.6f}\")\n",
    "print(f\"  Max: {X_train.max():.6f}\")\n",
    "print(f\"  Mean: {X_train.mean():.6f}\")\n",
    "\n",
    "print(f\"y_train dtype: {y_train.dtype}\")\n",
    "print(f\"y_train unique values: {np.unique(y_train)}\")\n",
    "print(f\"y_train range: {y_train.min()} to {y_train.max()}\")\n",
    "\n",
    "# Check for data issues\n",
    "print(f\"X_train has NaN: {np.isnan(X_train).any()}\")\n",
    "print(f\"X_train has inf: {np.isinf(X_train).any()}\")\n",
    "print(f\"y_train has NaN: {np.isnan(y_train).any()}\")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Input(shape=(X.shape[1],)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'), \n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),  # Explicit binary crossentropy\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nTraining model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "      tf.keras.callbacks.EarlyStopping(\n",
    "      monitor='val_loss',          # Monitor validation loss\n",
    "      patience=5,                  # Stop if no improvement for 5 epochs\n",
    "      restore_best_weights=True,   # Restore best weights when stopped\n",
    "      verbose=1 )     \n",
    "    ]\n",
    ")\n",
    "\n",
    "test_accuracy = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"\\n🎯 Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"✅ Model ready for testing!\")\n",
    "full_test = [\n",
    "    # Wine 1\n",
    "    {'text': '2023', 'x': 52, 'y': 182, 'h': 18},\n",
    "    {'text': 'PENFOLDS', 'x': 148, 'y': 182, 'h': 20}, \n",
    "    {'text': 'Shiraz', 'x': 285, 'y': 182, 'h': 18},\n",
    "    {'text': 'Barossa Valley', 'x': 425, 'y': 182, 'h': 16},\n",
    "    {'text': '85', 'x': 612, 'y': 182, 'h': 18},\n",
    "    \n",
    "    {'text': 'Gloubi', 'x': 612, 'y': 2000, 'h': 22},\n",
    "\n",
    "\n",
    "    # Wine 2 - different row\n",
    "    {'text': '2022', 'x': 52, 'y': 800, 'h': 18},\n",
    "    {'text': 'NAUTILUS', 'x': 148, 'y': 800, 'h': 20},\n",
    "    {'text': 'Sauvignon Blanc', 'x': 285, 'y': 800, 'h': 18},\n",
    "    {'text': 'Marlborough NZ', 'x': 425, 'y': 800, 'h': 16},\n",
    "    {'text': '65', 'x': 612, 'y': 800, 'h': 18}\n",
    "]\n",
    "\n",
    "full_tokens = [enrichor.enrich_token(token) for token in full_test]\n",
    "X_full = create_pairwise_features(full_tokens, vectorizer=vectorizer)\n",
    "\n",
    "print(\"Pairs\", X_full)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predictions_full = model.predict(X_full, verbose=0).flatten()\n",
    "\n",
    "\n",
    "# wine_df_full = pairwise_predictions_to_wine_entries(full_tokens, predictions_full, threshold=0.8)\n",
    "\n",
    "# print(\"🍷 TWO WINE TEST:\")\n",
    "# print(f\"\\nFound {len(wine_df_full)} wines - Expected: 2\")\n",
    "\n",
    "# wine_df_full\n",
    "\n",
    "# on# Test different thresholds\n",
    "# print(\"🔍 TESTING DIFFERENT THRESHOLDS:\")\n",
    "\n",
    "# for threshold in [0.3, 0.5, 0.7, 0.8, 0.9]:\n",
    "#     wine_df_test = pairwise_predictions_to_wine_entries(full_tokens, predictions_full, threshold=threshold)\n",
    "#     print(f\"Threshold {threshold}: Found {len(wine_df_test)} wines\")\n",
    "\n",
    "# # Check actual predictions for cross-wine pairs\n",
    "# print(f\"\\n📊 CROSS-WINE PREDICTIONS (should be low):\")\n",
    "# wine1_indices = [0, 1, 2, 3, 4]  # First 5 tokens (wine 1)\n",
    "# wine2_indices = [5, 6, 7, 8, 9]  # Next 5 tokens (wine 2)\n",
    "\n",
    "# pair_idx = 0\n",
    "# cross_wine_preds = []\n",
    "# for i in range(len(full_tokens)):\n",
    "#     for j in range(i + 1, len(full_tokens)):\n",
    "#         # Check if this is a cross-wine pair\n",
    "#         wine1_token = i in wine1_indices\n",
    "#         wine2_token = j in wine2_indices\n",
    "#         is_cross_wine = (wine1_token and j in wine2_indices) or (wine2_token and i in wine1_indices)\n",
    "        \n",
    "#         if is_cross_wine and pair_idx < len(predictions_full):\n",
    "#             pred = predictions_full[pair_idx]\n",
    "#             cross_wine_preds.append(pred)\n",
    "#             print(f\"  {pred:.3f} | '{full_tokens[i]['text']}' (wine1) ↔ '{full_tokens[j]['text']}' (wine2)\")\n",
    "        \n",
    "#         pair_idx += 1\n",
    "\n",
    "# print(f\"\\nCross-wine pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ediction stats:\")\n",
    "# print(f\"  Min: {min(cross_wine_preds):.3f}\")\n",
    "# print(f\"  Max: {max(cross_wine_preds):.3f}\")\n",
    "# print(f\"  Mean: {np.mean(cross_wine_preds):.3f}\")\n",
    "# print(f\"  Above 0.5: {sum(1 for p in cross_wine_preds if p > 0.5)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c4324",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a520dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tr/dev/cellar-ai/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Extracted 52 tokens\n",
      "[{'text': 'WHITE WINES', 'x': 78, 'y': 25, 'h': 20, 'confidence': 0.9992150187175544}, {'text': 'YEAR', 'x': 50, 'y': 63, 'h': 20, 'confidence': 0.9999305009841919}, {'text': 'WINE', 'x': 105, 'y': 64, 'h': 18, 'confidence': 0.9986971020698547}, {'text': 'REGION', 'x': 347, 'y': 64, 'h': 24, 'confidence': 0.999713926243581}, {'text': 'GLASS', 'x': 441, 'y': 63, 'h': 20, 'confidence': 0.9917610159672245}, {'text': 'BOTTLE', 'x': 507, 'y': 63, 'h': 20, 'confidence': 0.9995592499186086}, {'text': '2023', 'x': 46, 'y': 103, 'h': 20, 'confidence': 0.7124162596457525}, {'text': 'NAUTILUS Sauvignon Blanc', 'x': 171, 'y': 103, 'h': 20, 'confidence': 0.9833118674577895}, {'text': 'Marlborough NZ', 'x': 369, 'y': 102, 'h': 21, 'confidence': 0.9930145629335138}, {'text': '16', 'x': 469, 'y': 103, 'h': 20, 'confidence': 0.9999787580544308}, {'text': '77', 'x': 510, 'y': 103, 'h': 20, 'confidence': 0.9999828884223854}, {'text': '2022', 'x': 46, 'y': 123, 'h': 20, 'confidence': 0.9999984502792358}, {'text': 'BALTER Chardonnay', 'x': 148, 'y': 123, 'h': 26, 'confidence': 0.9924271395526064}, {'text': 'Adelaide Hills', 'x': 362, 'y': 123, 'h': 20, 'confidence': 0.8755739577539859}, {'text': '18', 'x': 469, 'y': 123, 'h': 20, 'confidence': 0.9999947737947846}, {'text': '88', 'x': 510, 'y': 123, 'h': 20, 'confidence': 0.9999988198884456}, {'text': '2024', 'x': 46, 'y': 141, 'h': 20, 'confidence': 0.9999983906745911}, {'text': 'FREYCINET Riesling', 'x': 148, 'y': 141, 'h': 26, 'confidence': 0.9998854094058514}, {'text': 'Tasmania', 'x': 349, 'y': 142, 'h': 18, 'confidence': 0.9999259889995445}, {'text': '15', 'x': 469, 'y': 141, 'h': 20, 'confidence': 0.9999118299314287}, {'text': '75', 'x': 510, 'y': 141, 'h': 20, 'confidence': 0.9999763978464146}, {'text': '2023', 'x': 46, 'y': 161, 'h': 20, 'confidence': 0.7124162596457525}, {'text': 'CANTINE Pinot Grigio', 'x': 151, 'y': 162, 'h': 24, 'confidence': 0.9870968900685445}, {'text': 'Toscana Italy', 'x': 361, 'y': 162, 'h': 24, 'confidence': 0.9813391745234754}, {'text': '17', 'x': 468, 'y': 160, 'h': 24, 'confidence': 0.9999576005336721}, {'text': '82', 'x': 510, 'y': 161, 'h': 20, 'confidence': 0.9999987355947788}, {'text': 'RED WINES', 'x': 71, 'y': 219, 'h': 20, 'confidence': 0.9950678137066361}, {'text': 'YEAR', 'x': 50, 'y': 257, 'h': 20, 'confidence': 0.9999305009841919}, {'text': 'WINE', 'x': 105, 'y': 258, 'h': 18, 'confidence': 0.9986971020698547}, {'text': 'REGION', 'x': 347, 'y': 258, 'h': 24, 'confidence': 0.999713926243581}, {'text': 'GLASS', 'x': 441, 'y': 257, 'h': 20, 'confidence': 0.9917610159672245}, {'text': 'BOTTLE', 'x': 507, 'y': 257, 'h': 20, 'confidence': 0.9995592499186086}, {'text': '2021', 'x': 45, 'y': 297, 'h': 20, 'confidence': 0.9999697804450989}, {'text': 'PENFOLDS Shiraz', 'x': 140, 'y': 297, 'h': 20, 'confidence': 0.9924805391847973}, {'text': 'Barossa Valley', 'x': 367, 'y': 298, 'h': 24, 'confidence': 0.9878354377725055}, {'text': '22', 'x': 469, 'y': 297, 'h': 20, 'confidence': 0.9999990727694587}, {'text': '110', 'x': 511, 'y': 298, 'h': 18, 'confidence': 0.998932421207428}, {'text': '2020', 'x': 46, 'y': 316, 'h': 18, 'confidence': 0.999258816242218}, {'text': 'ANTINORI Chianti', 'x': 138, 'y': 315, 'h': 20, 'confidence': 0.9940244969288536}, {'text': 'Toscana Italy', 'x': 361, 'y': 317, 'h': 20, 'confidence': 0.9933262277931103}, {'text': '19', 'x': 469, 'y': 315, 'h': 20, 'confidence': 0.9999916549341934}, {'text': '95', 'x': 510, 'y': 316, 'h': 18, 'confidence': 0.7498644512509517}, {'text': '2022', 'x': 46, 'y': 335, 'h': 20, 'confidence': 0.9999973773956299}, {'text': 'WYNNS Cabernet', 'x': 138, 'y': 335, 'h': 20, 'confidence': 0.9998397966304597}, {'text': 'Coonawarra', 'x': 358, 'y': 337, 'h': 16, 'confidence': 0.9971950812251756}, {'text': '24', 'x': 469, 'y': 335, 'h': 20, 'confidence': 0.9999998314126102}, {'text': '120', 'x': 510, 'y': 335, 'h': 20, 'confidence': 0.9997567745917729}, {'text': '2019', 'x': 45, 'y': 355, 'h': 20, 'confidence': 0.9999976754188538}, {'text': 'CLOUDY BAY Pinot Noir', 'x': 159, 'y': 355, 'h': 20, 'confidence': 0.7470839833888732}, {'text': 'Central Otago', 'x': 363, 'y': 356, 'h': 26, 'confidence': 0.9988916602522486}, {'text': '26', 'x': 469, 'y': 355, 'h': 20, 'confidence': 0.9999900533582403}, {'text': '130', 'x': 510, 'y': 355, 'h': 20, 'confidence': 0.9998509942465166}]\n",
      "✅ Tokens enriched\n",
      "🔗 Created 1298 pairs\n",
      "✅ 130 pairs predicted as SAME GROUP\n",
      "❌ 1168 pairs predicted as DIFFERENT GROUP\n",
      "\n",
      "🔍 DETECTED 2 WINE GROUPS\n",
      "==================================================\n",
      "\n",
      "🍷 WINE 2:\n",
      "   YEAR | WINE | REGION | GLASS | BOTTLE\n",
      "\n",
      "🍷 WINE 3:\n",
      "   2021 🗓️ | 2019 🗓️ | 2023 🗓️ | 2022 🗓️ | 2023 🗓️ | 2024 🗓️ | 2020 🗓️ | 2022 🗓️ | YEAR | RED WINES | WINE | ANTINORI Chianti | WYNNS Cabernet | PENFOLDS Shiraz | BALTER Chardonnay | FREYCINET Riesling | CANTINE Pinot Grigio | CLOUDY BAY Pinot Noir | NAUTILUS Sauvignon Blanc | REGION | tasmania | coonawarra | Toscana Italy | adelaide hills | central otago | barossa valley | Marlborough NZ | GLASS | 24 💰 | 22 💰 | 19 💰 | 26 💰 | 16 💰 | BOTTLE | 77 💰 | 120 💰 | 88 💰 | 95 💰 | 75 💰 | 130 💰 | 110 💰\n",
      "\n",
      "🔍 TOP CONFIDENT PREDICTIONS:\n",
      "------------------------------\n",
      "✅ SAME GROUP (top 5):\n",
      "   1.000 | 'BOTTLE' ↔ '110'\n",
      "   1.000 | 'BOTTLE' ↔ '2020'\n",
      "   1.000 | 'BOTTLE' ↔ 'PENFOLDS Shiraz'\n",
      "   1.000 | 'BOTTLE' ↔ '2021'\n",
      "   1.000 | '22' ↔ 'central otago'\n",
      "\n",
      "❌ DIFFERENT GROUP (top 5):\n",
      "   0.000 | '88' ✗ 'barossa valley'\n",
      "   0.000 | '88' ✗ 'REGION'\n",
      "   0.000 | 'Toscana Italy' ✗ '2019'\n",
      "   0.000 | '17' ✗ '82'\n",
      "   0.000 | '18' ✗ 'barossa valley'\n",
      "\n",
      "🎉 DONE! Found 2 wines\n"
     ]
    }
   ],
   "source": [
    "# # Make predictions\n",
    "\n",
    "tokens = extractor.extract_tokens('data/menus/menu_test.png')\n",
    "print(f\"📄 Extracted {len(tokens)} tokens\")\n",
    "print(tokens)\n",
    "# Enrich tokens\n",
    "tokens = [enrichor.enrich_token(token) for token in tokens]\n",
    "print(f\"✅ Tokens enriched\")\n",
    "\n",
    "# Create features\n",
    "X = create_pairwise_features(tokens, vectorizer=vectorizer)\n",
    "print(f\"🔗 Created {X.shape[0]} pairs\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X, verbose=0).flatten()\n",
    "\n",
    "# # # Show prediction stats\n",
    "same_group = np.sum(predictions > 0.5)\n",
    "different_group = np.sum(predictions <= 0.5)\n",
    "print(f\"✅ {same_group} pairs predicted as SAME GROUP\")\n",
    "print(f\"❌ {different_group} pairs predicted as DIFFERENT GROUP\")\n",
    "\n",
    "# Create adjacency matrix for grouping\n",
    "n_tokens = len(tokens)\n",
    "adjacency = np.zeros((n_tokens, n_tokens))\n",
    "\n",
    "# # Fill adjacency matrix from predictions\n",
    "pair_idx = 0\n",
    "for i in range(n_tokens):\n",
    "   for j in range(i + 1, n_tokens):\n",
    "       # Skip if pair was filtered out during feature creation\n",
    "       if pair_idx < len(predictions) and predictions[pair_idx] > 0.5:\n",
    "           adjacency[i][j] = 1\n",
    "           adjacency[j][i] = 1\n",
    "       if pair_idx < len(predictions):\n",
    "           pair_idx += 1\n",
    "\n",
    "# # Find connected components (groups)\n",
    "visited = [False] * n_tokens\n",
    "groups = []\n",
    "\n",
    "def dfs(node, current_group):\n",
    "   visited[node] = True\n",
    "   current_group.append(node)\n",
    "   for neighbor in range(n_tokens):\n",
    "       if adjacency[node][neighbor] == 1 and not visited[neighbor]:\n",
    "           dfs(neighbor, current_group)\n",
    "\n",
    "for i in range(n_tokens):\n",
    "   if not visited[i]:\n",
    "       current_group = []\n",
    "       dfs(i, current_group)\n",
    "       groups.append(current_group)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n🔍 DETECTED {len([g for g in groups if len(g) > 1])} WINE GROUPS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for group_idx, group in enumerate(groups):\n",
    "   if len(group) == 1:\n",
    "       continue  # Skip single tokens\n",
    "       \n",
    "   print(f\"\\n🍷 WINE {group_idx + 1}:\")\n",
    "   \n",
    "   # Sort tokens by x position (left to right)\n",
    "   group_tokens = [tokens[i] for i in group]\n",
    "   group_tokens.sort(key=lambda x: x['x'])\n",
    "   \n",
    "   wine_text = []\n",
    "   for token in group_tokens:\n",
    "       text = token['text']\n",
    "       if token.get('is_vintage'):\n",
    "           text += \" 🗓️\"\n",
    "       elif token.get('is_varietal_red'):\n",
    "           text += \" 🍷\"  \n",
    "       elif token.get('is_varietal_white'):\n",
    "           text += \" 🥂\"\n",
    "       elif token.get('is_price'):\n",
    "           text += \" 💰\"\n",
    "       wine_text.append(text)\n",
    "   \n",
    "   print(f\"   {' | '.join(wine_text)}\")\n",
    "\n",
    "# Show top confident predictions\n",
    "print(f\"\\n🔍 TOP CONFIDENT PREDICTIONS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Get pair info for top predictions\n",
    "pair_info = []\n",
    "pair_idx = 0\n",
    "for i in range(n_tokens):\n",
    "   for j in range(i + 1, n_tokens):\n",
    "       if pair_idx < len(predictions):\n",
    "           pair_info.append((i, j, predictions[pair_idx]))\n",
    "           pair_idx += 1\n",
    "\n",
    "# Sort by confidence\n",
    "pair_info.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"✅ SAME GROUP (top 5):\")\n",
    "count = 0\n",
    "for i, j, conf in pair_info:\n",
    "   if conf > 0.5 and count < 5:\n",
    "       print(f\"   {conf:.3f} | '{tokens[i]['text']}' ↔ '{tokens[j]['text']}'\")\n",
    "       count += 1\n",
    "\n",
    "print(\"\\n❌ DIFFERENT GROUP (top 5):\")\n",
    "count = 0\n",
    "for i, j, conf in reversed(pair_info[-10:]):\n",
    "   if conf < 0.5 and count < 5:\n",
    "       print(f\"   {conf:.3f} | '{tokens[i]['text']}' ✗ '{tokens[j]['text']}'\")\n",
    "       count += 1\n",
    "\n",
    "print(f\"\\n🎉 DONE! Found {len([g for g in groups if len(g) > 1])} wines\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e06baf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 TRAINING MINIMAL SPATIAL MODEL:\n",
      "X_minimal shape: (3, 1)\n",
      "X_minimal data: [[0. ]\n",
      " [0.1]\n",
      " [0.1]]\n",
      "y_minimal: [1. 0.]\n",
      "Training minimal model on 100 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tr/dev/cellar-ai/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Minimal model results:\n",
      "  Same row (y_diff≈0): 0.544 (should be >0.5)\n",
      "  Diff row (y_diff=0.1): 0.541 (should be <0.5)\n",
      "  Final accuracy: 0.625\n",
      "❌ Even minimal model failed - fundamental issue with approach\n"
     ]
    }
   ],
   "source": [
    "# Debug 3: Train a minimal spatial-only model (FIXED)\n",
    "import random\n",
    "\n",
    "\n",
    "print(f\"\\n🔄 TRAINING MINIMAL SPATIAL MODEL:\")\n",
    "\n",
    "def create_minimal_spatial_features(tokens):\n",
    "    \"\"\"Only Y difference as feature\"\"\"\n",
    "    features = []\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(i + 1, len(tokens)):\n",
    "            y_diff = abs(tokens[i]['y'] - tokens[j]['y'])\n",
    "            features.append([float(y_diff / 1000.0)])  # Ensure float type\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# Create test data\n",
    "debug_tokens = [\n",
    "    {'text': 'A', 'x': 100, 'y': 100, 'h': 18},  # Same row\n",
    "    {'text': 'B', 'x': 200, 'y': 100, 'h': 18},  # Same row  \n",
    "    {'text': 'C', 'x': 100, 'y': 200, 'h': 18},  # Different row\n",
    "]\n",
    "\n",
    "X_minimal = create_minimal_spatial_features(debug_tokens)\n",
    "y_minimal = np.array([1.0, 0.0], dtype=np.float32)  # A↔B same row=1, A↔C diff row=0\n",
    "\n",
    "print(f\"X_minimal shape: {X_minimal.shape}\")\n",
    "print(f\"X_minimal data: {X_minimal}\")\n",
    "print(f\"y_minimal: {y_minimal}\")\n",
    "\n",
    "minimal_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(8, input_shape=(1,), activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "minimal_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create more training data for the minimal model\n",
    "X_train_minimal = []\n",
    "y_train_minimal = []\n",
    "\n",
    "for same_row in [True, False]:\n",
    "    for _ in range(50):  # 50 examples each\n",
    "        if same_row:\n",
    "            y1, y2 = 100, 100 + random.randint(-5, 5)  # Same row with small variation\n",
    "            label = 1.0\n",
    "        else:\n",
    "            y1, y2 = 100, 100 + random.randint(50, 500)  # Different rows\n",
    "            label = 0.0\n",
    "            \n",
    "        y_diff = abs(y1 - y2) / 1000.0\n",
    "        X_train_minimal.append([y_diff])\n",
    "        y_train_minimal.append(label)\n",
    "\n",
    "X_train_minimal = np.array(X_train_minimal, dtype=np.float32)\n",
    "y_train_minimal = np.array(y_train_minimal, dtype=np.float32)\n",
    "\n",
    "print(f\"Training minimal model on {len(X_train_minimal)} examples...\")\n",
    "history_minimal = minimal_model.fit(\n",
    "    X_train_minimal, y_train_minimal, \n",
    "    epochs=50, \n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Test minimal model\n",
    "test_preds = minimal_model.predict(X_minimal, verbose=0)\n",
    "print(f\"\\nMinimal model results:\")\n",
    "print(f\"  Same row (y_diff≈0): {test_preds[0][0]:.3f} (should be >0.5)\")\n",
    "print(f\"  Diff row (y_diff=0.1): {test_preds[1][0]:.3f} (should be <0.5)\")\n",
    "print(f\"  Final accuracy: {history_minimal.history['accuracy'][-1]:.3f}\")\n",
    "\n",
    "if test_preds[0][0] > 0.5 and test_preds[1][0] < 0.5:\n",
    "    print(\"✅ Minimal model learned spatial pattern correctly!\")\n",
    "    print(\"❌ Problem is in your complex model - too many features confusing it\")\n",
    "else:\n",
    "    print(\"❌ Even minimal model failed - fundamental issue with approach\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
